{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thu4n/testing-model-notebook/blob/main/Copy_of_Lenet_MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKdbVuigmbPa"
      },
      "source": [
        "# Environment preparations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c416ykO-nzv-",
        "outputId": "82f9363f-4cf5-4122-d6f2-6e521034201e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpCDLfNi2uzg",
        "outputId": "e1d3edc9-97fb-4452-b442-0e6ee3d45c10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.9.16 (main, Dec  7 2022, 01:11:51) \n",
            "[GCC 9.4.0]\n",
            "2.11.0\n",
            "2.11.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from six.moves import urllib\n",
        "import tempfile\n",
        "import glob\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "# Examine software versions\n",
        "print(__import__('sys').version)\n",
        "print(tf.__version__)\n",
        "print(tf.keras.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrZw5TN3ottE",
        "outputId": "ee6416e2-8e01-43d6-c840-a086fb49c522"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ],
      "source": [
        "# Utilizing GPU for training\n",
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "print(\"Num GPUs Available: \", len(physical_devices))\n",
        "if (len(physical_devices) > 0):\n",
        "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GuGjnVK3Rcq"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4nnnxWRmuNI"
      },
      "source": [
        "## Loading dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54UjMQXy8Duf",
        "outputId": "40b51eab-2579-4672-e98e-f14854669f09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A_100.npy  A_304.npy  B_151.npy  B_355.npy  C_19.npy   C_46.npy   D_250.npy\n",
            "A_101.npy  A_305.npy  B_152.npy  B_356.npy  C_1.npy    C_47.npy   D_251.npy\n",
            "A_102.npy  A_306.npy  B_153.npy  B_357.npy  C_200.npy  C_48.npy   D_252.npy\n",
            "A_103.npy  A_307.npy  B_154.npy  B_358.npy  C_201.npy  C_49.npy   D_253.npy\n",
            "A_104.npy  A_308.npy  B_155.npy  B_359.npy  C_202.npy  C_4.npy\t  D_254.npy\n",
            "A_105.npy  A_309.npy  B_156.npy  B_35.npy   C_203.npy  C_50.npy   D_255.npy\n",
            "A_106.npy  A_30.npy   B_157.npy  B_360.npy  C_204.npy  C_51.npy   D_256.npy\n",
            "A_107.npy  A_310.npy  B_158.npy  B_361.npy  C_205.npy  C_52.npy   D_257.npy\n",
            "A_108.npy  A_311.npy  B_159.npy  B_362.npy  C_206.npy  C_53.npy   D_258.npy\n",
            "A_109.npy  A_312.npy  B_15.npy\t B_363.npy  C_207.npy  C_54.npy   D_259.npy\n",
            "A_10.npy   A_313.npy  B_160.npy  B_364.npy  C_208.npy  C_55.npy   D_25.npy\n",
            "A_110.npy  A_314.npy  B_161.npy  B_365.npy  C_209.npy  C_56.npy   D_260.npy\n",
            "A_111.npy  A_315.npy  B_162.npy  B_366.npy  C_20.npy   C_57.npy   D_261.npy\n",
            "A_112.npy  A_316.npy  B_163.npy  B_367.npy  C_210.npy  C_58.npy   D_262.npy\n",
            "A_113.npy  A_317.npy  B_164.npy  B_368.npy  C_211.npy  C_59.npy   D_263.npy\n",
            "A_114.npy  A_318.npy  B_165.npy  B_369.npy  C_212.npy  C_5.npy\t  D_264.npy\n",
            "A_115.npy  A_319.npy  B_166.npy  B_36.npy   C_213.npy  C_60.npy   D_265.npy\n",
            "A_116.npy  A_31.npy   B_167.npy  B_370.npy  C_214.npy  C_61.npy   D_266.npy\n",
            "A_117.npy  A_320.npy  B_168.npy  B_371.npy  C_215.npy  C_62.npy   D_267.npy\n",
            "A_118.npy  A_321.npy  B_169.npy  B_372.npy  C_216.npy  C_63.npy   D_268.npy\n",
            "A_119.npy  A_322.npy  B_16.npy\t B_373.npy  C_217.npy  C_64.npy   D_269.npy\n",
            "A_11.npy   A_323.npy  B_170.npy  B_374.npy  C_218.npy  C_65.npy   D_26.npy\n",
            "A_120.npy  A_324.npy  B_171.npy  B_375.npy  C_219.npy  C_66.npy   D_270.npy\n",
            "A_121.npy  A_325.npy  B_172.npy  B_376.npy  C_21.npy   C_67.npy   D_271.npy\n",
            "A_122.npy  A_326.npy  B_173.npy  B_377.npy  C_220.npy  C_68.npy   D_272.npy\n",
            "A_123.npy  A_327.npy  B_174.npy  B_378.npy  C_221.npy  C_69.npy   D_273.npy\n",
            "A_124.npy  A_328.npy  B_175.npy  B_379.npy  C_222.npy  C_6.npy\t  D_274.npy\n",
            "A_125.npy  A_329.npy  B_176.npy  B_37.npy   C_223.npy  C_70.npy   D_275.npy\n",
            "A_126.npy  A_32.npy   B_177.npy  B_380.npy  C_224.npy  C_71.npy   D_276.npy\n",
            "A_127.npy  A_330.npy  B_178.npy  B_381.npy  C_225.npy  C_72.npy   D_277.npy\n",
            "A_128.npy  A_331.npy  B_179.npy  B_382.npy  C_226.npy  C_73.npy   D_278.npy\n",
            "A_129.npy  A_332.npy  B_17.npy\t B_383.npy  C_227.npy  C_74.npy   D_279.npy\n",
            "A_12.npy   A_333.npy  B_180.npy  B_384.npy  C_228.npy  C_75.npy   D_27.npy\n",
            "A_130.npy  A_334.npy  B_181.npy  B_385.npy  C_229.npy  C_76.npy   D_280.npy\n",
            "A_131.npy  A_335.npy  B_182.npy  B_386.npy  C_22.npy   C_77.npy   D_281.npy\n",
            "A_132.npy  A_336.npy  B_183.npy  B_387.npy  C_230.npy  C_78.npy   D_282.npy\n",
            "A_133.npy  A_337.npy  B_184.npy  B_388.npy  C_231.npy  C_79.npy   D_283.npy\n",
            "A_134.npy  A_338.npy  B_185.npy  B_389.npy  C_232.npy  C_7.npy\t  D_284.npy\n",
            "A_135.npy  A_339.npy  B_186.npy  B_38.npy   C_233.npy  C_80.npy   D_285.npy\n",
            "A_136.npy  A_33.npy   B_187.npy  B_390.npy  C_234.npy  C_81.npy   D_286.npy\n",
            "A_137.npy  A_340.npy  B_188.npy  B_391.npy  C_235.npy  C_82.npy   D_287.npy\n",
            "A_138.npy  A_341.npy  B_189.npy  B_392.npy  C_236.npy  C_83.npy   D_288.npy\n",
            "A_139.npy  A_342.npy  B_18.npy\t B_393.npy  C_237.npy  C_84.npy   D_289.npy\n",
            "A_13.npy   A_343.npy  B_190.npy  B_394.npy  C_238.npy  C_85.npy   D_28.npy\n",
            "A_140.npy  A_344.npy  B_191.npy  B_395.npy  C_239.npy  C_86.npy   D_290.npy\n",
            "A_141.npy  A_345.npy  B_192.npy  B_396.npy  C_23.npy   C_87.npy   D_291.npy\n",
            "A_142.npy  A_346.npy  B_193.npy  B_397.npy  C_240.npy  C_88.npy   D_292.npy\n",
            "A_143.npy  A_347.npy  B_194.npy  B_398.npy  C_241.npy  C_89.npy   D_293.npy\n",
            "A_144.npy  A_348.npy  B_195.npy  B_399.npy  C_242.npy  C_8.npy\t  D_294.npy\n",
            "A_145.npy  A_349.npy  B_196.npy  B_39.npy   C_243.npy  C_90.npy   D_295.npy\n",
            "A_146.npy  A_34.npy   B_197.npy  B_3.npy    C_244.npy  C_91.npy   D_296.npy\n",
            "A_147.npy  A_350.npy  B_198.npy  B_40.npy   C_245.npy  C_92.npy   D_297.npy\n",
            "A_148.npy  A_351.npy  B_199.npy  B_41.npy   C_246.npy  C_93.npy   D_298.npy\n",
            "A_149.npy  A_352.npy  B_19.npy\t B_42.npy   C_247.npy  C_94.npy   D_299.npy\n",
            "A_14.npy   A_353.npy  B_1.npy\t B_43.npy   C_248.npy  C_95.npy   D_29.npy\n",
            "A_150.npy  A_354.npy  B_200.npy  B_44.npy   C_249.npy  C_96.npy   D_2.npy\n",
            "A_151.npy  A_355.npy  B_201.npy  B_45.npy   C_24.npy   C_97.npy   D_300.npy\n",
            "A_152.npy  A_356.npy  B_202.npy  B_46.npy   C_250.npy  C_98.npy   D_301.npy\n",
            "A_153.npy  A_357.npy  B_203.npy  B_47.npy   C_251.npy  C_99.npy   D_302.npy\n",
            "A_154.npy  A_358.npy  B_204.npy  B_48.npy   C_252.npy  C_9.npy\t  D_303.npy\n",
            "A_155.npy  A_359.npy  B_205.npy  B_49.npy   C_253.npy  D_100.npy  D_304.npy\n",
            "A_156.npy  A_35.npy   B_206.npy  B_4.npy    C_254.npy  D_101.npy  D_305.npy\n",
            "A_157.npy  A_360.npy  B_207.npy  B_50.npy   C_255.npy  D_102.npy  D_306.npy\n",
            "A_158.npy  A_361.npy  B_208.npy  B_51.npy   C_256.npy  D_103.npy  D_307.npy\n",
            "A_159.npy  A_362.npy  B_209.npy  B_52.npy   C_257.npy  D_104.npy  D_308.npy\n",
            "A_15.npy   A_363.npy  B_20.npy\t B_53.npy   C_258.npy  D_105.npy  D_309.npy\n",
            "A_160.npy  A_364.npy  B_210.npy  B_54.npy   C_259.npy  D_106.npy  D_30.npy\n",
            "A_161.npy  A_365.npy  B_211.npy  B_55.npy   C_25.npy   D_107.npy  D_310.npy\n",
            "A_162.npy  A_366.npy  B_212.npy  B_56.npy   C_260.npy  D_108.npy  D_311.npy\n",
            "A_163.npy  A_367.npy  B_213.npy  B_57.npy   C_261.npy  D_109.npy  D_312.npy\n",
            "A_164.npy  A_368.npy  B_214.npy  B_58.npy   C_262.npy  D_10.npy   D_313.npy\n",
            "A_165.npy  A_369.npy  B_215.npy  B_59.npy   C_263.npy  D_110.npy  D_314.npy\n",
            "A_166.npy  A_36.npy   B_216.npy  B_5.npy    C_264.npy  D_111.npy  D_315.npy\n",
            "A_167.npy  A_370.npy  B_217.npy  B_60.npy   C_265.npy  D_112.npy  D_316.npy\n",
            "A_168.npy  A_371.npy  B_218.npy  B_61.npy   C_266.npy  D_113.npy  D_317.npy\n",
            "A_169.npy  A_372.npy  B_219.npy  B_62.npy   C_267.npy  D_114.npy  D_318.npy\n",
            "A_16.npy   A_373.npy  B_21.npy\t B_63.npy   C_268.npy  D_115.npy  D_319.npy\n",
            "A_170.npy  A_374.npy  B_220.npy  B_64.npy   C_269.npy  D_116.npy  D_31.npy\n",
            "A_171.npy  A_375.npy  B_221.npy  B_65.npy   C_26.npy   D_117.npy  D_320.npy\n",
            "A_172.npy  A_376.npy  B_222.npy  B_66.npy   C_270.npy  D_118.npy  D_321.npy\n",
            "A_173.npy  A_377.npy  B_223.npy  B_67.npy   C_271.npy  D_119.npy  D_322.npy\n",
            "A_174.npy  A_378.npy  B_224.npy  B_68.npy   C_272.npy  D_11.npy   D_323.npy\n",
            "A_175.npy  A_379.npy  B_225.npy  B_69.npy   C_273.npy  D_120.npy  D_324.npy\n",
            "A_176.npy  A_37.npy   B_226.npy  B_6.npy    C_274.npy  D_121.npy  D_325.npy\n",
            "A_177.npy  A_380.npy  B_227.npy  B_70.npy   C_275.npy  D_122.npy  D_326.npy\n",
            "A_178.npy  A_381.npy  B_228.npy  B_71.npy   C_276.npy  D_123.npy  D_327.npy\n",
            "A_179.npy  A_382.npy  B_229.npy  B_72.npy   C_277.npy  D_124.npy  D_328.npy\n",
            "A_17.npy   A_383.npy  B_22.npy\t B_73.npy   C_278.npy  D_125.npy  D_329.npy\n",
            "A_180.npy  A_384.npy  B_230.npy  B_74.npy   C_279.npy  D_126.npy  D_32.npy\n",
            "A_181.npy  A_385.npy  B_231.npy  B_75.npy   C_27.npy   D_127.npy  D_330.npy\n",
            "A_182.npy  A_386.npy  B_232.npy  B_76.npy   C_280.npy  D_128.npy  D_331.npy\n",
            "A_183.npy  A_387.npy  B_233.npy  B_77.npy   C_281.npy  D_129.npy  D_332.npy\n",
            "A_184.npy  A_388.npy  B_234.npy  B_78.npy   C_282.npy  D_12.npy   D_333.npy\n",
            "A_185.npy  A_389.npy  B_235.npy  B_79.npy   C_283.npy  D_130.npy  D_334.npy\n",
            "A_186.npy  A_38.npy   B_236.npy  B_7.npy    C_284.npy  D_131.npy  D_335.npy\n",
            "A_187.npy  A_390.npy  B_237.npy  B_80.npy   C_285.npy  D_132.npy  D_336.npy\n",
            "A_188.npy  A_391.npy  B_238.npy  B_81.npy   C_286.npy  D_133.npy  D_337.npy\n",
            "A_189.npy  A_392.npy  B_239.npy  B_82.npy   C_287.npy  D_134.npy  D_338.npy\n",
            "A_18.npy   A_393.npy  B_23.npy\t B_83.npy   C_288.npy  D_135.npy  D_339.npy\n",
            "A_190.npy  A_394.npy  B_240.npy  B_84.npy   C_289.npy  D_136.npy  D_33.npy\n",
            "A_191.npy  A_395.npy  B_241.npy  B_85.npy   C_28.npy   D_137.npy  D_340.npy\n",
            "A_192.npy  A_396.npy  B_242.npy  B_86.npy   C_290.npy  D_138.npy  D_341.npy\n",
            "A_193.npy  A_39.npy   B_243.npy  B_87.npy   C_291.npy  D_139.npy  D_342.npy\n",
            "A_194.npy  A_3.npy    B_244.npy  B_88.npy   C_292.npy  D_13.npy   D_343.npy\n",
            "A_195.npy  A_40.npy   B_245.npy  B_89.npy   C_293.npy  D_140.npy  D_344.npy\n",
            "A_196.npy  A_41.npy   B_246.npy  B_8.npy    C_294.npy  D_141.npy  D_345.npy\n",
            "A_197.npy  A_42.npy   B_247.npy  B_90.npy   C_295.npy  D_142.npy  D_346.npy\n",
            "A_198.npy  A_43.npy   B_248.npy  B_91.npy   C_296.npy  D_143.npy  D_347.npy\n",
            "A_199.npy  A_44.npy   B_249.npy  B_92.npy   C_297.npy  D_144.npy  D_348.npy\n",
            "A_19.npy   A_45.npy   B_24.npy\t B_93.npy   C_298.npy  D_145.npy  D_349.npy\n",
            "A_1.npy    A_46.npy   B_250.npy  B_94.npy   C_299.npy  D_146.npy  D_34.npy\n",
            "A_200.npy  A_47.npy   B_251.npy  B_95.npy   C_29.npy   D_147.npy  D_350.npy\n",
            "A_201.npy  A_48.npy   B_252.npy  B_96.npy   C_2.npy    D_148.npy  D_351.npy\n",
            "A_202.npy  A_49.npy   B_253.npy  B_97.npy   C_300.npy  D_149.npy  D_352.npy\n",
            "A_203.npy  A_4.npy    B_254.npy  B_98.npy   C_301.npy  D_14.npy   D_353.npy\n",
            "A_204.npy  A_50.npy   B_255.npy  B_99.npy   C_302.npy  D_150.npy  D_354.npy\n",
            "A_205.npy  A_51.npy   B_256.npy  B_9.npy    C_303.npy  D_151.npy  D_355.npy\n",
            "A_206.npy  A_52.npy   B_257.npy  C_100.npy  C_304.npy  D_152.npy  D_356.npy\n",
            "A_207.npy  A_53.npy   B_258.npy  C_101.npy  C_305.npy  D_153.npy  D_357.npy\n",
            "A_208.npy  A_54.npy   B_259.npy  C_102.npy  C_306.npy  D_154.npy  D_358.npy\n",
            "A_209.npy  A_55.npy   B_25.npy\t C_103.npy  C_307.npy  D_155.npy  D_359.npy\n",
            "A_20.npy   A_56.npy   B_260.npy  C_104.npy  C_308.npy  D_156.npy  D_35.npy\n",
            "A_210.npy  A_57.npy   B_261.npy  C_105.npy  C_309.npy  D_157.npy  D_360.npy\n",
            "A_211.npy  A_58.npy   B_262.npy  C_106.npy  C_30.npy   D_158.npy  D_361.npy\n",
            "A_212.npy  A_59.npy   B_263.npy  C_107.npy  C_310.npy  D_159.npy  D_362.npy\n",
            "A_213.npy  A_5.npy    B_264.npy  C_108.npy  C_311.npy  D_15.npy   D_363.npy\n",
            "A_214.npy  A_60.npy   B_265.npy  C_109.npy  C_312.npy  D_160.npy  D_364.npy\n",
            "A_215.npy  A_61.npy   B_266.npy  C_10.npy   C_313.npy  D_161.npy  D_365.npy\n",
            "A_216.npy  A_62.npy   B_267.npy  C_110.npy  C_314.npy  D_162.npy  D_366.npy\n",
            "A_217.npy  A_63.npy   B_268.npy  C_111.npy  C_315.npy  D_163.npy  D_367.npy\n",
            "A_218.npy  A_64.npy   B_269.npy  C_112.npy  C_316.npy  D_164.npy  D_368.npy\n",
            "A_219.npy  A_65.npy   B_26.npy\t C_113.npy  C_317.npy  D_165.npy  D_369.npy\n",
            "A_21.npy   A_66.npy   B_270.npy  C_114.npy  C_318.npy  D_166.npy  D_36.npy\n",
            "A_220.npy  A_67.npy   B_271.npy  C_115.npy  C_319.npy  D_167.npy  D_370.npy\n",
            "A_221.npy  A_68.npy   B_272.npy  C_116.npy  C_31.npy   D_168.npy  D_371.npy\n",
            "A_222.npy  A_69.npy   B_273.npy  C_117.npy  C_320.npy  D_169.npy  D_372.npy\n",
            "A_223.npy  A_6.npy    B_274.npy  C_118.npy  C_321.npy  D_16.npy   D_373.npy\n",
            "A_224.npy  A_70.npy   B_275.npy  C_119.npy  C_322.npy  D_170.npy  D_374.npy\n",
            "A_225.npy  A_71.npy   B_276.npy  C_11.npy   C_323.npy  D_171.npy  D_375.npy\n",
            "A_226.npy  A_72.npy   B_277.npy  C_120.npy  C_324.npy  D_172.npy  D_376.npy\n",
            "A_227.npy  A_73.npy   B_278.npy  C_121.npy  C_325.npy  D_173.npy  D_377.npy\n",
            "A_228.npy  A_74.npy   B_279.npy  C_122.npy  C_326.npy  D_174.npy  D_378.npy\n",
            "A_229.npy  A_75.npy   B_27.npy\t C_123.npy  C_327.npy  D_175.npy  D_379.npy\n",
            "A_22.npy   A_76.npy   B_280.npy  C_124.npy  C_328.npy  D_176.npy  D_37.npy\n",
            "A_230.npy  A_77.npy   B_281.npy  C_125.npy  C_329.npy  D_177.npy  D_380.npy\n",
            "A_231.npy  A_78.npy   B_282.npy  C_126.npy  C_32.npy   D_178.npy  D_381.npy\n",
            "A_232.npy  A_79.npy   B_283.npy  C_127.npy  C_330.npy  D_179.npy  D_382.npy\n",
            "A_233.npy  A_7.npy    B_284.npy  C_128.npy  C_331.npy  D_17.npy   D_383.npy\n",
            "A_234.npy  A_80.npy   B_285.npy  C_129.npy  C_332.npy  D_180.npy  D_384.npy\n",
            "A_235.npy  A_81.npy   B_286.npy  C_12.npy   C_333.npy  D_181.npy  D_385.npy\n",
            "A_236.npy  A_82.npy   B_287.npy  C_130.npy  C_334.npy  D_182.npy  D_386.npy\n",
            "A_237.npy  A_83.npy   B_288.npy  C_131.npy  C_335.npy  D_183.npy  D_387.npy\n",
            "A_238.npy  A_84.npy   B_289.npy  C_132.npy  C_336.npy  D_184.npy  D_388.npy\n",
            "A_239.npy  A_85.npy   B_28.npy\t C_133.npy  C_337.npy  D_185.npy  D_389.npy\n",
            "A_23.npy   A_86.npy   B_290.npy  C_134.npy  C_338.npy  D_186.npy  D_38.npy\n",
            "A_240.npy  A_87.npy   B_291.npy  C_135.npy  C_339.npy  D_187.npy  D_390.npy\n",
            "A_241.npy  A_88.npy   B_292.npy  C_136.npy  C_33.npy   D_188.npy  D_391.npy\n",
            "A_242.npy  A_89.npy   B_293.npy  C_137.npy  C_340.npy  D_189.npy  D_39.npy\n",
            "A_243.npy  A_8.npy    B_294.npy  C_138.npy  C_341.npy  D_18.npy   D_3.npy\n",
            "A_244.npy  A_90.npy   B_295.npy  C_139.npy  C_342.npy  D_190.npy  D_40.npy\n",
            "A_245.npy  A_91.npy   B_296.npy  C_13.npy   C_343.npy  D_191.npy  D_41.npy\n",
            "A_246.npy  A_92.npy   B_297.npy  C_140.npy  C_344.npy  D_192.npy  D_42.npy\n",
            "A_247.npy  A_93.npy   B_298.npy  C_141.npy  C_345.npy  D_193.npy  D_43.npy\n",
            "A_248.npy  A_94.npy   B_299.npy  C_142.npy  C_346.npy  D_194.npy  D_44.npy\n",
            "A_249.npy  A_95.npy   B_29.npy\t C_143.npy  C_347.npy  D_195.npy  D_45.npy\n",
            "A_24.npy   A_96.npy   B_2.npy\t C_144.npy  C_348.npy  D_196.npy  D_46.npy\n",
            "A_250.npy  A_97.npy   B_300.npy  C_145.npy  C_349.npy  D_197.npy  D_47.npy\n",
            "A_251.npy  A_98.npy   B_301.npy  C_146.npy  C_34.npy   D_198.npy  D_48.npy\n",
            "A_252.npy  A_99.npy   B_302.npy  C_147.npy  C_350.npy  D_199.npy  D_49.npy\n",
            "A_253.npy  A_9.npy    B_303.npy  C_148.npy  C_351.npy  D_19.npy   D_4.npy\n",
            "A_254.npy  B_100.npy  B_304.npy  C_149.npy  C_352.npy  D_1.npy\t  D_50.npy\n",
            "A_255.npy  B_101.npy  B_305.npy  C_14.npy   C_353.npy  D_200.npy  D_51.npy\n",
            "A_256.npy  B_102.npy  B_306.npy  C_150.npy  C_354.npy  D_201.npy  D_52.npy\n",
            "A_257.npy  B_103.npy  B_307.npy  C_151.npy  C_355.npy  D_202.npy  D_53.npy\n",
            "A_258.npy  B_104.npy  B_308.npy  C_152.npy  C_356.npy  D_203.npy  D_54.npy\n",
            "A_259.npy  B_105.npy  B_309.npy  C_153.npy  C_357.npy  D_204.npy  D_55.npy\n",
            "A_25.npy   B_106.npy  B_30.npy\t C_154.npy  C_358.npy  D_205.npy  D_56.npy\n",
            "A_260.npy  B_107.npy  B_310.npy  C_155.npy  C_359.npy  D_206.npy  D_57.npy\n",
            "A_261.npy  B_108.npy  B_311.npy  C_156.npy  C_35.npy   D_207.npy  D_58.npy\n",
            "A_262.npy  B_109.npy  B_312.npy  C_157.npy  C_360.npy  D_208.npy  D_59.npy\n",
            "A_263.npy  B_10.npy   B_313.npy  C_158.npy  C_361.npy  D_209.npy  D_5.npy\n",
            "A_264.npy  B_110.npy  B_314.npy  C_159.npy  C_362.npy  D_20.npy   D_60.npy\n",
            "A_265.npy  B_111.npy  B_315.npy  C_15.npy   C_363.npy  D_210.npy  D_61.npy\n",
            "A_266.npy  B_112.npy  B_316.npy  C_160.npy  C_364.npy  D_211.npy  D_62.npy\n",
            "A_267.npy  B_113.npy  B_317.npy  C_161.npy  C_365.npy  D_212.npy  D_63.npy\n",
            "A_268.npy  B_114.npy  B_318.npy  C_162.npy  C_366.npy  D_213.npy  D_64.npy\n",
            "A_269.npy  B_115.npy  B_319.npy  C_163.npy  C_367.npy  D_214.npy  D_65.npy\n",
            "A_26.npy   B_116.npy  B_31.npy\t C_164.npy  C_368.npy  D_215.npy  D_66.npy\n",
            "A_270.npy  B_117.npy  B_320.npy  C_165.npy  C_369.npy  D_216.npy  D_67.npy\n",
            "A_271.npy  B_118.npy  B_321.npy  C_166.npy  C_36.npy   D_217.npy  D_68.npy\n",
            "A_272.npy  B_119.npy  B_322.npy  C_167.npy  C_370.npy  D_218.npy  D_69.npy\n",
            "A_273.npy  B_11.npy   B_323.npy  C_168.npy  C_371.npy  D_219.npy  D_6.npy\n",
            "A_274.npy  B_120.npy  B_324.npy  C_169.npy  C_372.npy  D_21.npy   D_70.npy\n",
            "A_275.npy  B_121.npy  B_325.npy  C_16.npy   C_373.npy  D_220.npy  D_71.npy\n",
            "A_276.npy  B_122.npy  B_326.npy  C_170.npy  C_374.npy  D_221.npy  D_72.npy\n",
            "A_277.npy  B_123.npy  B_327.npy  C_171.npy  C_375.npy  D_222.npy  D_73.npy\n",
            "A_278.npy  B_124.npy  B_328.npy  C_172.npy  C_376.npy  D_223.npy  D_74.npy\n",
            "A_279.npy  B_125.npy  B_329.npy  C_173.npy  C_377.npy  D_224.npy  D_75.npy\n",
            "A_27.npy   B_126.npy  B_32.npy\t C_174.npy  C_378.npy  D_225.npy  D_76.npy\n",
            "A_280.npy  B_127.npy  B_330.npy  C_175.npy  C_379.npy  D_226.npy  D_77.npy\n",
            "A_281.npy  B_128.npy  B_331.npy  C_176.npy  C_37.npy   D_227.npy  D_78.npy\n",
            "A_282.npy  B_129.npy  B_332.npy  C_177.npy  C_380.npy  D_228.npy  D_79.npy\n",
            "A_283.npy  B_12.npy   B_333.npy  C_178.npy  C_381.npy  D_229.npy  D_7.npy\n",
            "A_284.npy  B_130.npy  B_334.npy  C_179.npy  C_382.npy  D_22.npy   D_80.npy\n",
            "A_285.npy  B_131.npy  B_335.npy  C_17.npy   C_383.npy  D_230.npy  D_81.npy\n",
            "A_286.npy  B_132.npy  B_336.npy  C_180.npy  C_384.npy  D_231.npy  D_82.npy\n",
            "A_287.npy  B_133.npy  B_337.npy  C_181.npy  C_385.npy  D_232.npy  D_83.npy\n",
            "A_288.npy  B_134.npy  B_338.npy  C_182.npy  C_386.npy  D_233.npy  D_84.npy\n",
            "A_289.npy  B_135.npy  B_339.npy  C_183.npy  C_387.npy  D_234.npy  D_85.npy\n",
            "A_28.npy   B_136.npy  B_33.npy\t C_184.npy  C_388.npy  D_235.npy  D_86.npy\n",
            "A_290.npy  B_137.npy  B_340.npy  C_185.npy  C_389.npy  D_236.npy  D_87.npy\n",
            "A_291.npy  B_138.npy  B_341.npy  C_186.npy  C_38.npy   D_237.npy  D_88.npy\n",
            "A_292.npy  B_139.npy  B_342.npy  C_187.npy  C_390.npy  D_238.npy  D_89.npy\n",
            "A_293.npy  B_13.npy   B_343.npy  C_188.npy  C_391.npy  D_239.npy  D_8.npy\n",
            "A_294.npy  B_140.npy  B_344.npy  C_189.npy  C_392.npy  D_23.npy   D_90.npy\n",
            "A_295.npy  B_141.npy  B_345.npy  C_18.npy   C_393.npy  D_240.npy  D_91.npy\n",
            "A_296.npy  B_142.npy  B_346.npy  C_190.npy  C_394.npy  D_241.npy  D_92.npy\n",
            "A_297.npy  B_143.npy  B_347.npy  C_191.npy  C_395.npy  D_242.npy  D_93.npy\n",
            "A_298.npy  B_144.npy  B_348.npy  C_192.npy  C_39.npy   D_243.npy  D_94.npy\n",
            "A_299.npy  B_145.npy  B_349.npy  C_193.npy  C_3.npy    D_244.npy  D_95.npy\n",
            "A_29.npy   B_146.npy  B_34.npy\t C_194.npy  C_40.npy   D_245.npy  D_96.npy\n",
            "A_2.npy    B_147.npy  B_350.npy  C_195.npy  C_41.npy   D_246.npy  D_97.npy\n",
            "A_300.npy  B_148.npy  B_351.npy  C_196.npy  C_42.npy   D_247.npy  D_98.npy\n",
            "A_301.npy  B_149.npy  B_352.npy  C_197.npy  C_43.npy   D_248.npy  D_99.npy\n",
            "A_302.npy  B_14.npy   B_353.npy  C_198.npy  C_44.npy   D_249.npy  D_9.npy\n",
            "A_303.npy  B_150.npy  B_354.npy  C_199.npy  C_45.npy   D_24.npy\n"
          ]
        }
      ],
      "source": [
        "external_path = '/content/drive/MyDrive/PREP_N5_CSI_DATA'\n",
        "!ls $external_path # Checking directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9N98YVy68QRL"
      },
      "outputs": [],
      "source": [
        "# Creating list of filenames\n",
        "filenames = glob.glob(external_path + \"/*.npy\")\n",
        "filenames_p = [i.split('/')[-1] for i in filenames]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmBKMN445iDR"
      },
      "outputs": [],
      "source": [
        "!rm -rf ./csi_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iis-Ii7r-dlx"
      },
      "outputs": [],
      "source": [
        "# Copying data to local environment for quicker loading to numpy\n",
        "!cp -r $external_path ./csi_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r01npDWeOauu"
      },
      "outputs": [],
      "source": [
        "# Creating empty lists to store data and labels\n",
        "all_data = []\n",
        "all_labels = []\n",
        "\n",
        "# Reading data from numpy files and adding to empty list\n",
        "matrlen = 500\n",
        "for f in filenames_p:\n",
        "  matr_abs = np.load('./csi_data' + '/' + f)\n",
        "  filtermatr = np.zeros((52, matrlen))\n",
        "  N = 5\n",
        "  temp = 0\n",
        "  matr_abs = matr_abs.transpose()\n",
        "  for x in range(52):\n",
        "    for y in range(matrlen):\n",
        "      if (y + 1 <= matrlen - N):\n",
        "        temp = 0\n",
        "        for z in range(y, y + N):\n",
        "          temp = temp + matr_abs[x][z]\n",
        "        filtermatr[x][y] = temp / N\n",
        "      else:\n",
        "        temp = 0\n",
        "        for w in range(y - N, y):\n",
        "          temp = temp + matr_abs[x][w]\n",
        "        filtermatr[x][y] = temp / N\n",
        "  filtermatr = filtermatr.transpose()\n",
        "\n",
        "\n",
        "  file_data = filtermatr\n",
        "  thresh = np.zeros(500)\n",
        "  pack_avg = np.zeros(500)\n",
        "  sub_avg = np.zeros(500)\n",
        "  sub_max = np.zeros(500)\n",
        "  r = 0.9\n",
        "  d_relo = np.zeros((500, 52))\n",
        "  for i in range(500):\n",
        "    sub_avg[i] = sum(file_data[i, :]) / 52\n",
        "  start_p = 0  # starting point\n",
        "  end_p = 499  # ending point\n",
        "  avg = sum(sub_avg) / 500  # get average value of 500 packets with 52 subcarriers for each\n",
        "\n",
        "  for j in range(500):\n",
        "      pack_avg[j] = avg  # create a packet's average value line\n",
        "      if sub_avg[j] < avg:\n",
        "          sub_avg[j] = 2 * avg - sub_avg[j]\n",
        "      sub_max[j] = np.max(sub_avg)  # get the largest value\n",
        "\n",
        "  while r >= 0.4:  # variable 'r' is thresh ratio\n",
        "      listr = []\n",
        "      for k in range(500):\n",
        "          thresh[k] = sub_max[k] * r + (1 - r) * pack_avg[k]\n",
        "          if sub_avg[k] >= thresh[0]:\n",
        "            listr.append(k)\n",
        "      start_p = listr[0]\n",
        "      end_p = listr[len(listr) - 1]\n",
        "      if end_p - start_p >= 210:\n",
        "        break\n",
        "      r = r - 0.01\n",
        "    # show variables\n",
        "  cent = int((start_p + end_p) / 2)\n",
        "    # print(cent)\n",
        "  var = cent - 250  # shifting condition\n",
        "\n",
        "    # d_left: leftovers data; d_relo: relocated data\n",
        "  if var > 0:  # shift to left\n",
        "        d_left = file_data[0:var, :]\n",
        "        d_relo[500 - var:500, :] = d_left\n",
        "        d_relo[0:500 - var] = file_data[var:500]\n",
        "  elif var < 0:  # shift to right\n",
        "        var = -var\n",
        "        d_left = file_data[500 - var:500, :]\n",
        "        d_relo[0:var] = d_left\n",
        "        d_relo[var:500, :] = file_data[0:500 - var, :]\n",
        "  p = d_relo\n",
        "  data_in = p.flatten()\n",
        "  all_data.append(data_in)\n",
        "  all_labels.append(f.split('_')[0])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TtIVG3lMcKOJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b58f1e5c-786f-411b-8d62-7be32394c0a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C_121.npy\n",
            "C_164.npy\n",
            "C_102.npy\n",
            "C_109.npy\n",
            "C_169.npy\n",
            "C_156.npy\n",
            "C_179.npy\n",
            "C_180.npy\n",
            "C_170.npy\n",
            "C_95.npy\n",
            "C_185.npy\n",
            "C_163.npy\n",
            "C_136.npy\n",
            "C_148.npy\n",
            "C_118.npy\n",
            "C_112.npy\n",
            "C_141.npy\n",
            "C_239.npy\n",
            "C_248.npy\n",
            "C_264.npy\n",
            "C_308.npy\n",
            "C_289.npy\n",
            "C_309.npy\n",
            "C_228.npy\n",
            "C_224.npy\n",
            "C_267.npy\n",
            "C_220.npy\n",
            "C_215.npy\n",
            "C_214.npy\n",
            "C_296.npy\n",
            "C_255.npy\n",
            "C_253.npy\n",
            "C_286.npy\n",
            "C_304.npy\n",
            "C_275.npy\n",
            "C_251.npy\n",
            "C_231.npy\n",
            "C_276.npy\n",
            "C_273.npy\n",
            "C_290.npy\n",
            "C_203.npy\n",
            "C_279.npy\n",
            "C_210.npy\n",
            "C_259.npy\n",
            "C_269.npy\n",
            "C_302.npy\n",
            "C_208.npy\n",
            "C_280.npy\n",
            "C_226.npy\n",
            "C_205.npy\n",
            "C_254.npy\n",
            "C_298.npy\n",
            "C_234.npy\n",
            "C_263.npy\n",
            "C_232.npy\n",
            "C_219.npy\n",
            "C_283.npy\n",
            "C_272.npy\n",
            "C_278.npy\n",
            "C_218.npy\n",
            "C_216.npy\n",
            "C_252.npy\n",
            "C_285.npy\n",
            "C_209.npy\n",
            "C_306.npy\n",
            "C_281.npy\n",
            "C_284.npy\n",
            "C_318.npy\n",
            "C_288.npy\n",
            "C_299.npy\n",
            "C_301.npy\n",
            "C_271.npy\n",
            "C_243.npy\n",
            "C_229.npy\n",
            "C_316.npy\n",
            "C_211.npy\n",
            "C_217.npy\n",
            "C_282.npy\n",
            "C_300.npy\n",
            "C_314.npy\n",
            "C_292.npy\n",
            "C_241.npy\n",
            "C_295.npy\n",
            "C_227.npy\n",
            "C_213.npy\n",
            "C_249.npy\n",
            "C_204.npy\n",
            "C_240.npy\n",
            "C_244.npy\n",
            "C_238.npy\n",
            "C_305.npy\n",
            "C_206.npy\n",
            "C_260.npy\n",
            "C_242.npy\n",
            "C_268.npy\n",
            "C_293.npy\n",
            "C_311.npy\n",
            "C_257.npy\n",
            "C_270.npy\n",
            "C_207.npy\n",
            "C_317.npy\n",
            "C_222.npy\n",
            "C_246.npy\n",
            "C_310.npy\n",
            "C_230.npy\n",
            "C_212.npy\n",
            "C_291.npy\n",
            "C_315.npy\n",
            "C_250.npy\n",
            "C_265.npy\n",
            "C_223.npy\n",
            "C_287.npy\n",
            "C_313.npy\n",
            "C_237.npy\n",
            "C_303.npy\n",
            "C_247.npy\n",
            "C_258.npy\n",
            "C_225.npy\n",
            "C_235.npy\n",
            "C_266.npy\n",
            "C_233.npy\n",
            "C_297.npy\n",
            "C_294.npy\n",
            "C_307.npy\n",
            "C_277.npy\n",
            "C_274.npy\n",
            "C_245.npy\n",
            "C_262.npy\n",
            "C_256.npy\n",
            "C_261.npy\n",
            "C_312.npy\n",
            "C_236.npy\n",
            "C_221.npy\n",
            "C_333.npy\n",
            "C_335.npy\n",
            "C_319.npy\n",
            "C_380.npy\n",
            "D_11.npy\n",
            "C_340.npy\n",
            "D_30.npy\n",
            "C_341.npy\n",
            "C_386.npy\n",
            "C_344.npy\n",
            "C_356.npy\n",
            "C_324.npy\n",
            "C_328.npy\n",
            "C_325.npy\n",
            "D_7.npy\n",
            "C_330.npy\n",
            "D_23.npy\n",
            "C_321.npy\n",
            "C_351.npy\n",
            "C_327.npy\n",
            "D_37.npy\n",
            "D_18.npy\n",
            "D_28.npy\n",
            "C_334.npy\n",
            "C_320.npy\n",
            "C_369.npy\n",
            "C_374.npy\n",
            "C_366.npy\n",
            "C_353.npy\n",
            "C_379.npy\n",
            "C_342.npy\n",
            "D_36.npy\n",
            "D_45.npy\n",
            "D_6.npy\n",
            "D_1.npy\n",
            "C_382.npy\n",
            "C_361.npy\n",
            "D_24.npy\n",
            "D_39.npy\n",
            "C_367.npy\n",
            "C_362.npy\n",
            "D_20.npy\n",
            "D_19.npy\n",
            "D_9.npy\n",
            "C_349.npy\n",
            "D_46.npy\n",
            "C_377.npy\n",
            "D_38.npy\n",
            "C_373.npy\n",
            "C_378.npy\n",
            "C_360.npy\n",
            "C_375.npy\n",
            "C_363.npy\n",
            "C_332.npy\n",
            "D_27.npy\n",
            "D_41.npy\n",
            "C_391.npy\n",
            "C_388.npy\n",
            "D_32.npy\n",
            "D_31.npy\n",
            "C_371.npy\n",
            "D_4.npy\n",
            "C_394.npy\n",
            "C_329.npy\n",
            "C_384.npy\n",
            "C_357.npy\n",
            "C_385.npy\n",
            "C_392.npy\n",
            "C_352.npy\n",
            "C_389.npy\n",
            "D_14.npy\n",
            "C_339.npy\n",
            "D_16.npy\n",
            "C_331.npy\n",
            "C_326.npy\n",
            "D_12.npy\n",
            "D_17.npy\n",
            "D_25.npy\n",
            "D_35.npy\n",
            "D_10.npy\n",
            "C_350.npy\n",
            "C_343.npy\n",
            "C_368.npy\n",
            "D_3.npy\n",
            "D_26.npy\n",
            "D_42.npy\n",
            "C_372.npy\n",
            "D_5.npy\n",
            "D_40.npy\n",
            "C_337.npy\n",
            "C_365.npy\n",
            "C_370.npy\n",
            "D_44.npy\n",
            "C_364.npy\n",
            "D_15.npy\n",
            "C_390.npy\n",
            "C_387.npy\n",
            "D_33.npy\n",
            "D_2.npy\n",
            "C_346.npy\n",
            "C_393.npy\n",
            "D_8.npy\n",
            "C_345.npy\n",
            "C_395.npy\n",
            "D_43.npy\n",
            "C_376.npy\n",
            "C_381.npy\n",
            "C_348.npy\n",
            "C_358.npy\n",
            "C_383.npy\n",
            "D_29.npy\n",
            "C_355.npy\n",
            "C_354.npy\n",
            "D_13.npy\n",
            "D_21.npy\n",
            "D_34.npy\n",
            "C_323.npy\n",
            "D_22.npy\n",
            "C_359.npy\n",
            "C_347.npy\n",
            "C_338.npy\n",
            "C_322.npy\n",
            "C_336.npy\n",
            "D_139.npy\n",
            "D_110.npy\n",
            "D_83.npy\n",
            "D_140.npy\n",
            "D_101.npy\n",
            "D_59.npy\n",
            "D_47.npy\n",
            "D_141.npy\n",
            "D_162.npy\n",
            "D_147.npy\n",
            "D_160.npy\n",
            "D_150.npy\n",
            "D_111.npy\n",
            "D_51.npy\n",
            "D_118.npy\n",
            "D_106.npy\n",
            "D_80.npy\n",
            "D_138.npy\n",
            "D_167.npy\n",
            "D_161.npy\n",
            "D_96.npy\n",
            "D_76.npy\n",
            "D_50.npy\n",
            "D_163.npy\n",
            "D_49.npy\n",
            "D_73.npy\n",
            "D_60.npy\n",
            "D_148.npy\n",
            "D_62.npy\n",
            "D_79.npy\n",
            "D_94.npy\n",
            "D_109.npy\n",
            "D_63.npy\n",
            "D_144.npy\n",
            "D_97.npy\n",
            "D_142.npy\n",
            "D_69.npy\n",
            "D_108.npy\n",
            "D_156.npy\n",
            "D_151.npy\n",
            "D_72.npy\n",
            "D_135.npy\n",
            "D_82.npy\n",
            "D_70.npy\n",
            "D_152.npy\n",
            "D_129.npy\n",
            "D_145.npy\n",
            "D_134.npy\n",
            "D_71.npy\n",
            "D_78.npy\n",
            "D_92.npy\n",
            "D_55.npy\n",
            "D_53.npy\n",
            "D_159.npy\n",
            "D_153.npy\n",
            "D_87.npy\n",
            "D_136.npy\n",
            "D_113.npy\n",
            "D_84.npy\n",
            "D_120.npy\n",
            "D_75.npy\n",
            "D_64.npy\n",
            "D_168.npy\n",
            "D_102.npy\n",
            "D_61.npy\n",
            "D_81.npy\n",
            "D_66.npy\n",
            "D_104.npy\n",
            "D_133.npy\n",
            "D_112.npy\n",
            "D_166.npy\n",
            "D_116.npy\n",
            "D_165.npy\n",
            "D_88.npy\n",
            "D_131.npy\n",
            "D_98.npy\n",
            "D_126.npy\n",
            "D_93.npy\n",
            "D_54.npy\n",
            "D_173.npy\n",
            "D_149.npy\n",
            "D_119.npy\n",
            "D_103.npy\n",
            "D_123.npy\n",
            "D_158.npy\n",
            "D_56.npy\n",
            "D_121.npy\n",
            "D_115.npy\n",
            "D_100.npy\n",
            "D_86.npy\n",
            "D_130.npy\n",
            "D_90.npy\n",
            "D_125.npy\n",
            "D_99.npy\n",
            "D_124.npy\n",
            "D_95.npy\n",
            "D_67.npy\n",
            "D_57.npy\n",
            "D_157.npy\n",
            "D_65.npy\n",
            "D_164.npy\n",
            "D_117.npy\n",
            "D_114.npy\n",
            "D_154.npy\n",
            "D_172.npy\n",
            "D_143.npy\n",
            "D_89.npy\n",
            "D_137.npy\n",
            "D_128.npy\n",
            "D_74.npy\n",
            "D_48.npy\n",
            "D_52.npy\n",
            "D_169.npy\n",
            "D_68.npy\n",
            "D_146.npy\n",
            "D_107.npy\n",
            "D_85.npy\n",
            "D_58.npy\n",
            "D_127.npy\n",
            "D_155.npy\n",
            "D_170.npy\n",
            "D_122.npy\n",
            "D_132.npy\n",
            "D_77.npy\n",
            "D_91.npy\n",
            "D_171.npy\n",
            "D_105.npy\n",
            "D_273.npy\n",
            "D_293.npy\n",
            "D_267.npy\n",
            "D_287.npy\n",
            "D_183.npy\n",
            "D_174.npy\n",
            "D_215.npy\n",
            "D_250.npy\n",
            "D_198.npy\n",
            "D_265.npy\n",
            "D_270.npy\n",
            "D_259.npy\n",
            "D_221.npy\n",
            "D_232.npy\n",
            "D_301.npy\n",
            "D_300.npy\n",
            "D_227.npy\n",
            "D_211.npy\n",
            "D_179.npy\n",
            "D_276.npy\n",
            "D_244.npy\n",
            "D_207.npy\n",
            "D_297.npy\n",
            "D_264.npy\n",
            "D_283.npy\n",
            "D_257.npy\n",
            "D_180.npy\n",
            "D_275.npy\n",
            "D_233.npy\n",
            "D_261.npy\n",
            "D_210.npy\n",
            "D_252.npy\n",
            "D_274.npy\n",
            "D_242.npy\n",
            "D_247.npy\n",
            "D_288.npy\n",
            "D_189.npy\n",
            "D_219.npy\n",
            "D_201.npy\n",
            "D_284.npy\n",
            "D_188.npy\n",
            "D_224.npy\n",
            "D_269.npy\n",
            "D_253.npy\n",
            "D_177.npy\n",
            "D_237.npy\n",
            "D_295.npy\n",
            "D_279.npy\n",
            "D_208.npy\n",
            "D_296.npy\n",
            "D_258.npy\n",
            "D_238.npy\n",
            "D_245.npy\n",
            "D_241.npy\n",
            "D_290.npy\n",
            "D_246.npy\n",
            "D_192.npy\n",
            "D_196.npy\n",
            "D_243.npy\n",
            "D_277.npy\n",
            "D_195.npy\n",
            "D_191.npy\n",
            "D_298.npy\n",
            "D_263.npy\n",
            "D_178.npy\n",
            "D_234.npy\n",
            "D_271.npy\n",
            "D_266.npy\n",
            "D_213.npy\n",
            "D_291.npy\n",
            "D_281.npy\n",
            "D_240.npy\n",
            "D_285.npy\n",
            "D_187.npy\n",
            "D_286.npy\n",
            "D_268.npy\n",
            "D_186.npy\n",
            "D_202.npy\n",
            "D_212.npy\n",
            "D_229.npy\n",
            "D_175.npy\n",
            "D_222.npy\n",
            "D_209.npy\n",
            "D_223.npy\n",
            "D_217.npy\n",
            "D_256.npy\n",
            "D_205.npy\n",
            "D_231.npy\n",
            "D_282.npy\n",
            "D_225.npy\n",
            "D_193.npy\n",
            "D_262.npy\n",
            "D_235.npy\n",
            "D_218.npy\n",
            "D_249.npy\n",
            "D_280.npy\n",
            "D_230.npy\n",
            "D_239.npy\n",
            "D_185.npy\n",
            "D_214.npy\n",
            "D_194.npy\n",
            "D_176.npy\n",
            "D_204.npy\n",
            "D_197.npy\n",
            "D_294.npy\n",
            "D_181.npy\n",
            "D_228.npy\n",
            "D_299.npy\n",
            "D_216.npy\n",
            "D_302.npy\n",
            "D_255.npy\n",
            "D_289.npy\n",
            "D_190.npy\n",
            "D_182.npy\n",
            "D_248.npy\n",
            "D_278.npy\n",
            "D_199.npy\n",
            "D_292.npy\n",
            "D_200.npy\n",
            "D_236.npy\n",
            "D_254.npy\n",
            "D_226.npy\n",
            "D_251.npy\n",
            "D_203.npy\n",
            "D_206.npy\n",
            "D_272.npy\n",
            "D_220.npy\n",
            "D_260.npy\n",
            "D_184.npy\n",
            "D_320.npy\n",
            "D_308.npy\n",
            "D_387.npy\n",
            "B_10.npy\n",
            "D_370.npy\n",
            "D_332.npy\n",
            "D_376.npy\n",
            "D_330.npy\n",
            "D_331.npy\n",
            "D_336.npy\n",
            "D_381.npy\n",
            "D_315.npy\n",
            "D_390.npy\n",
            "D_386.npy\n",
            "D_365.npy\n",
            "D_338.npy\n",
            "D_344.npy\n",
            "D_343.npy\n",
            "D_368.npy\n",
            "D_310.npy\n",
            "D_374.npy\n",
            "D_379.npy\n",
            "D_378.npy\n",
            "D_328.npy\n",
            "D_385.npy\n",
            "D_346.npy\n",
            "D_309.npy\n",
            "B_8.npy\n",
            "D_325.npy\n",
            "D_312.npy\n",
            "D_383.npy\n",
            "D_348.npy\n",
            "D_384.npy\n",
            "D_327.npy\n",
            "D_361.npy\n",
            "D_377.npy\n",
            "D_380.npy\n",
            "D_350.npy\n",
            "D_342.npy\n",
            "D_375.npy\n",
            "B_3.npy\n",
            "D_367.npy\n",
            "D_389.npy\n",
            "D_333.npy\n",
            "B_11.npy\n",
            "D_319.npy\n",
            "B_9.npy\n",
            "D_304.npy\n",
            "D_324.npy\n",
            "D_349.npy\n",
            "D_352.npy\n",
            "D_355.npy\n",
            "D_366.npy\n",
            "D_303.npy\n",
            "D_316.npy\n",
            "D_354.npy\n",
            "D_305.npy\n",
            "D_341.npy\n",
            "D_323.npy\n",
            "D_322.npy\n",
            "D_313.npy\n",
            "B_2.npy\n",
            "D_357.npy\n",
            "D_340.npy\n",
            "D_306.npy\n",
            "D_369.npy\n",
            "D_345.npy\n",
            "D_329.npy\n",
            "D_314.npy\n",
            "D_334.npy\n",
            "D_371.npy\n",
            "B_5.npy\n",
            "D_326.npy\n",
            "D_382.npy\n",
            "D_307.npy\n",
            "D_360.npy\n",
            "D_362.npy\n",
            "D_321.npy\n",
            "D_364.npy\n",
            "B_13.npy\n",
            "D_372.npy\n",
            "D_317.npy\n",
            "D_363.npy\n",
            "D_353.npy\n",
            "D_337.npy\n",
            "D_311.npy\n",
            "D_356.npy\n",
            "D_391.npy\n",
            "D_373.npy\n",
            "B_4.npy\n",
            "B_12.npy\n",
            "B_1.npy\n",
            "D_359.npy\n",
            "D_358.npy\n",
            "D_351.npy\n",
            "D_388.npy\n",
            "D_347.npy\n",
            "B_6.npy\n",
            "D_335.npy\n",
            "D_318.npy\n",
            "D_339.npy\n",
            "B_7.npy\n",
            "B_23.npy\n",
            "B_27.npy\n",
            "B_45.npy\n",
            "B_40.npy\n",
            "B_35.npy\n",
            "B_51.npy\n",
            "B_22.npy\n",
            "B_17.npy\n",
            "B_15.npy\n",
            "B_33.npy\n",
            "B_52.npy\n",
            "B_47.npy\n",
            "B_50.npy\n",
            "B_26.npy\n",
            "B_36.npy\n",
            "B_38.npy\n",
            "B_42.npy\n",
            "B_41.npy\n",
            "B_24.npy\n",
            "B_14.npy\n",
            "B_37.npy\n",
            "B_19.npy\n",
            "B_49.npy\n",
            "B_32.npy\n",
            "B_28.npy\n",
            "B_43.npy\n",
            "B_46.npy\n",
            "B_44.npy\n",
            "B_21.npy\n",
            "B_20.npy\n",
            "B_25.npy\n",
            "B_48.npy\n",
            "B_29.npy\n",
            "B_18.npy\n",
            "B_31.npy\n",
            "B_34.npy\n",
            "B_30.npy\n",
            "B_16.npy\n",
            "B_39.npy\n",
            "B_53.npy\n",
            "B_80.npy\n",
            "B_93.npy\n",
            "B_86.npy\n",
            "B_91.npy\n",
            "B_68.npy\n",
            "B_83.npy\n",
            "B_70.npy\n",
            "B_72.npy\n",
            "B_71.npy\n",
            "B_69.npy\n",
            "B_55.npy\n",
            "B_75.npy\n",
            "B_77.npy\n",
            "B_61.npy\n",
            "B_90.npy\n",
            "B_89.npy\n",
            "B_59.npy\n",
            "B_67.npy\n",
            "B_88.npy\n",
            "B_58.npy\n",
            "B_62.npy\n",
            "B_82.npy\n",
            "B_92.npy\n",
            "B_85.npy\n",
            "B_54.npy\n",
            "B_66.npy\n",
            "B_57.npy\n",
            "B_63.npy\n",
            "B_79.npy\n",
            "B_65.npy\n",
            "B_73.npy\n",
            "B_64.npy\n",
            "B_56.npy\n",
            "B_84.npy\n",
            "B_74.npy\n",
            "B_81.npy\n",
            "B_60.npy\n",
            "B_78.npy\n",
            "B_87.npy\n",
            "B_76.npy\n",
            "B_94.npy\n",
            "B_105.npy\n",
            "B_96.npy\n",
            "B_124.npy\n",
            "B_101.npy\n",
            "B_106.npy\n",
            "B_133.npy\n",
            "B_122.npy\n",
            "B_112.npy\n",
            "B_121.npy\n",
            "B_99.npy\n",
            "B_135.npy\n",
            "B_100.npy\n",
            "B_123.npy\n",
            "B_95.npy\n",
            "B_114.npy\n",
            "B_118.npy\n",
            "B_117.npy\n",
            "B_108.npy\n",
            "B_107.npy\n",
            "B_98.npy\n",
            "B_120.npy\n",
            "B_129.npy\n",
            "B_128.npy\n",
            "B_126.npy\n",
            "B_134.npy\n",
            "B_119.npy\n",
            "B_111.npy\n",
            "B_104.npy\n",
            "B_109.npy\n",
            "B_113.npy\n",
            "B_97.npy\n",
            "B_127.npy\n",
            "B_131.npy\n",
            "B_125.npy\n",
            "B_102.npy\n",
            "B_132.npy\n",
            "B_116.npy\n",
            "B_115.npy\n",
            "B_103.npy\n",
            "B_130.npy\n",
            "B_110.npy\n",
            "B_136.npy\n",
            "B_163.npy\n",
            "B_162.npy\n",
            "B_164.npy\n",
            "B_161.npy\n",
            "B_156.npy\n",
            "B_140.npy\n",
            "B_139.npy\n",
            "B_166.npy\n",
            "B_158.npy\n",
            "B_154.npy\n",
            "B_149.npy\n",
            "B_141.npy\n",
            "B_171.npy\n",
            "B_165.npy\n",
            "B_147.npy\n",
            "B_170.npy\n",
            "B_168.npy\n",
            "B_160.npy\n",
            "B_174.npy\n",
            "B_159.npy\n",
            "B_146.npy\n",
            "B_172.npy\n",
            "B_144.npy\n",
            "B_143.npy\n",
            "B_173.npy\n",
            "B_167.npy\n",
            "B_151.npy\n",
            "B_138.npy\n",
            "B_153.npy\n",
            "B_145.npy\n",
            "B_137.npy\n",
            "B_148.npy\n",
            "B_155.npy\n",
            "B_157.npy\n",
            "B_150.npy\n",
            "B_152.npy\n",
            "B_169.npy\n",
            "B_142.npy\n",
            "B_190.npy\n",
            "B_179.npy\n",
            "B_202.npy\n",
            "B_185.npy\n",
            "B_200.npy\n",
            "B_189.npy\n",
            "B_177.npy\n",
            "B_196.npy\n",
            "B_193.npy\n",
            "B_187.npy\n",
            "B_181.npy\n",
            "B_184.npy\n",
            "B_208.npy\n",
            "B_204.npy\n",
            "B_198.npy\n",
            "B_186.npy\n",
            "B_180.npy\n",
            "B_183.npy\n",
            "B_194.npy\n",
            "B_178.npy\n",
            "B_191.npy\n",
            "B_188.npy\n",
            "B_209.npy\n",
            "B_182.npy\n",
            "B_175.npy\n",
            "B_206.npy\n",
            "B_207.npy\n",
            "B_203.npy\n",
            "B_195.npy\n",
            "B_192.npy\n",
            "B_211.npy\n",
            "B_210.npy\n",
            "B_201.npy\n",
            "B_197.npy\n",
            "B_176.npy\n",
            "B_205.npy\n",
            "B_199.npy\n",
            "B_227.npy\n",
            "B_215.npy\n",
            "B_238.npy\n",
            "B_231.npy\n",
            "B_212.npy\n",
            "B_248.npy\n",
            "B_223.npy\n",
            "B_239.npy\n",
            "B_217.npy\n",
            "B_250.npy\n",
            "B_220.npy\n",
            "B_229.npy\n",
            "B_234.npy\n",
            "B_228.npy\n",
            "B_232.npy\n",
            "B_214.npy\n",
            "B_237.npy\n",
            "B_233.npy\n",
            "B_242.npy\n",
            "B_236.npy\n",
            "B_244.npy\n",
            "B_249.npy\n",
            "B_224.npy\n",
            "B_219.npy\n",
            "B_213.npy\n",
            "B_243.npy\n",
            "B_241.npy\n",
            "B_240.npy\n",
            "B_246.npy\n",
            "B_245.npy\n",
            "B_222.npy\n",
            "B_216.npy\n",
            "B_235.npy\n",
            "B_251.npy\n",
            "B_230.npy\n",
            "B_218.npy\n",
            "B_247.npy\n",
            "B_226.npy\n",
            "B_221.npy\n",
            "B_225.npy\n",
            "B_291.npy\n",
            "B_255.npy\n",
            "B_290.npy\n",
            "B_266.npy\n",
            "B_257.npy\n",
            "B_274.npy\n",
            "B_269.npy\n",
            "B_275.npy\n",
            "B_252.npy\n",
            "B_288.npy\n",
            "B_289.npy\n",
            "B_268.npy\n",
            "B_273.npy\n",
            "B_256.npy\n",
            "B_277.npy\n",
            "B_285.npy\n",
            "B_279.npy\n",
            "B_264.npy\n",
            "B_270.npy\n",
            "B_276.npy\n",
            "B_267.npy\n",
            "B_258.npy\n",
            "B_287.npy\n",
            "B_284.npy\n",
            "B_261.npy\n",
            "B_271.npy\n",
            "B_272.npy\n",
            "B_286.npy\n",
            "B_283.npy\n",
            "B_254.npy\n",
            "B_259.npy\n",
            "B_263.npy\n",
            "B_260.npy\n",
            "B_282.npy\n",
            "B_253.npy\n",
            "B_262.npy\n",
            "B_265.npy\n",
            "B_278.npy\n",
            "B_281.npy\n",
            "B_280.npy\n",
            "B_311.npy\n",
            "B_324.npy\n",
            "B_309.npy\n",
            "B_328.npy\n",
            "B_313.npy\n",
            "B_295.npy\n",
            "B_300.npy\n",
            "B_306.npy\n",
            "B_299.npy\n",
            "B_330.npy\n",
            "B_297.npy\n",
            "B_329.npy\n",
            "B_322.npy\n",
            "B_315.npy\n",
            "B_327.npy\n",
            "B_314.npy\n",
            "B_307.npy\n",
            "B_325.npy\n",
            "B_305.npy\n",
            "B_321.npy\n",
            "B_302.npy\n",
            "B_319.npy\n",
            "B_298.npy\n",
            "B_294.npy\n",
            "B_293.npy\n",
            "B_310.npy\n",
            "B_326.npy\n",
            "B_308.npy\n",
            "B_296.npy\n",
            "B_292.npy\n",
            "B_303.npy\n",
            "B_312.npy\n",
            "B_317.npy\n",
            "B_318.npy\n",
            "B_323.npy\n",
            "B_304.npy\n",
            "B_320.npy\n",
            "B_301.npy\n",
            "B_316.npy\n",
            "B_334.npy\n",
            "B_358.npy\n",
            "B_362.npy\n",
            "B_336.npy\n",
            "B_355.npy\n",
            "B_337.npy\n",
            "B_338.npy\n",
            "B_343.npy\n",
            "B_360.npy\n",
            "B_349.npy\n",
            "B_333.npy\n",
            "B_367.npy\n",
            "B_353.npy\n",
            "B_363.npy\n",
            "B_342.npy\n",
            "B_365.npy\n",
            "B_350.npy\n",
            "B_344.npy\n",
            "B_361.npy\n",
            "B_352.npy\n",
            "B_339.npy\n",
            "B_335.npy\n",
            "B_364.npy\n",
            "B_348.npy\n",
            "B_354.npy\n",
            "B_345.npy\n",
            "B_340.npy\n",
            "B_347.npy\n",
            "B_346.npy\n",
            "B_332.npy\n",
            "B_366.npy\n",
            "B_368.npy\n",
            "B_331.npy\n",
            "B_341.npy\n",
            "B_351.npy\n",
            "B_359.npy\n",
            "B_357.npy\n",
            "B_356.npy\n",
            "B_375.npy\n",
            "B_383.npy\n",
            "B_373.npy\n",
            "B_389.npy\n",
            "B_378.npy\n",
            "B_372.npy\n",
            "B_371.npy\n",
            "B_386.npy\n",
            "B_377.npy\n",
            "B_397.npy\n",
            "B_399.npy\n",
            "B_388.npy\n",
            "B_384.npy\n",
            "B_370.npy\n",
            "B_395.npy\n",
            "B_376.npy\n",
            "B_396.npy\n",
            "B_374.npy\n",
            "B_380.npy\n",
            "B_398.npy\n",
            "B_393.npy\n",
            "B_391.npy\n",
            "B_385.npy\n",
            "B_387.npy\n",
            "B_382.npy\n",
            "B_390.npy\n",
            "B_369.npy\n",
            "B_392.npy\n",
            "B_381.npy\n",
            "B_379.npy\n",
            "B_394.npy\n",
            "A_39.npy\n",
            "A_11.npy\n",
            "A_45.npy\n",
            "A_46.npy\n",
            "A_13.npy\n",
            "A_38.npy\n",
            "A_12.npy\n",
            "A_7.npy\n",
            "A_53.npy\n",
            "A_41.npy\n",
            "A_49.npy\n",
            "A_40.npy\n",
            "A_42.npy\n",
            "A_25.npy\n",
            "A_50.npy\n",
            "A_35.npy\n",
            "A_36.npy\n",
            "A_19.npy\n",
            "A_31.npy\n",
            "A_8.npy\n",
            "A_6.npy\n",
            "A_43.npy\n",
            "A_28.npy\n",
            "A_51.npy\n",
            "A_10.npy\n",
            "A_44.npy\n",
            "A_29.npy\n",
            "A_3.npy\n",
            "A_27.npy\n",
            "A_20.npy\n",
            "A_14.npy\n",
            "A_32.npy\n",
            "A_33.npy\n",
            "A_23.npy\n",
            "A_30.npy\n",
            "A_9.npy\n",
            "A_52.npy\n",
            "A_48.npy\n",
            "A_24.npy\n",
            "A_1.npy\n",
            "A_26.npy\n",
            "A_47.npy\n",
            "A_22.npy\n",
            "A_37.npy\n",
            "A_15.npy\n",
            "A_4.npy\n",
            "A_2.npy\n",
            "A_17.npy\n",
            "A_34.npy\n",
            "A_16.npy\n",
            "A_18.npy\n",
            "A_5.npy\n",
            "A_21.npy\n",
            "A_61.npy\n",
            "A_136.npy\n",
            "A_112.npy\n",
            "A_127.npy\n",
            "A_63.npy\n",
            "A_150.npy\n",
            "A_83.npy\n",
            "A_75.npy\n",
            "A_95.npy\n",
            "A_58.npy\n",
            "A_88.npy\n",
            "A_71.npy\n",
            "A_102.npy\n",
            "A_132.npy\n",
            "A_78.npy\n",
            "A_84.npy\n",
            "A_141.npy\n",
            "A_118.npy\n",
            "A_65.npy\n",
            "A_77.npy\n",
            "A_96.npy\n",
            "A_105.npy\n",
            "A_160.npy\n",
            "A_156.npy\n",
            "A_122.npy\n",
            "A_79.npy\n",
            "A_143.npy\n",
            "A_60.npy\n",
            "A_81.npy\n",
            "A_108.npy\n",
            "A_109.npy\n",
            "A_97.npy\n",
            "A_138.npy\n",
            "A_90.npy\n",
            "A_72.npy\n",
            "A_139.npy\n",
            "A_91.npy\n",
            "A_93.npy\n",
            "A_144.npy\n",
            "A_142.npy\n",
            "A_147.npy\n",
            "A_148.npy\n",
            "A_89.npy\n",
            "A_125.npy\n",
            "A_126.npy\n",
            "A_64.npy\n",
            "A_120.npy\n",
            "A_137.npy\n",
            "A_154.npy\n",
            "A_121.npy\n",
            "A_80.npy\n",
            "A_85.npy\n",
            "A_124.npy\n",
            "A_159.npy\n",
            "A_98.npy\n",
            "A_151.npy\n",
            "A_157.npy\n",
            "A_70.npy\n",
            "A_135.npy\n",
            "A_131.npy\n",
            "A_66.npy\n",
            "A_146.npy\n",
            "A_110.npy\n",
            "A_153.npy\n",
            "A_128.npy\n",
            "A_59.npy\n",
            "A_158.npy\n",
            "A_101.npy\n",
            "A_155.npy\n",
            "A_67.npy\n",
            "A_113.npy\n",
            "A_62.npy\n",
            "A_56.npy\n",
            "A_123.npy\n",
            "A_100.npy\n",
            "A_133.npy\n",
            "A_145.npy\n",
            "A_107.npy\n",
            "A_82.npy\n",
            "A_106.npy\n",
            "A_111.npy\n",
            "A_92.npy\n",
            "A_116.npy\n",
            "A_76.npy\n",
            "A_115.npy\n",
            "A_117.npy\n",
            "A_57.npy\n",
            "A_152.npy\n",
            "A_54.npy\n",
            "A_130.npy\n",
            "A_104.npy\n",
            "A_73.npy\n",
            "A_129.npy\n",
            "A_68.npy\n",
            "A_103.npy\n",
            "A_134.npy\n",
            "A_114.npy\n",
            "A_74.npy\n",
            "A_149.npy\n",
            "A_140.npy\n",
            "A_87.npy\n",
            "A_94.npy\n",
            "A_69.npy\n",
            "A_119.npy\n",
            "A_99.npy\n",
            "A_86.npy\n",
            "A_55.npy\n",
            "A_208.npy\n",
            "A_176.npy\n",
            "A_248.npy\n",
            "A_231.npy\n",
            "A_174.npy\n",
            "A_214.npy\n",
            "A_186.npy\n",
            "A_252.npy\n",
            "A_206.npy\n",
            "A_259.npy\n",
            "A_202.npy\n",
            "A_172.npy\n",
            "A_230.npy\n",
            "A_204.npy\n",
            "A_236.npy\n",
            "A_219.npy\n",
            "A_264.npy\n",
            "A_200.npy\n",
            "A_188.npy\n",
            "A_217.npy\n",
            "A_226.npy\n",
            "A_268.npy\n",
            "A_274.npy\n",
            "A_209.npy\n",
            "A_187.npy\n",
            "A_184.npy\n",
            "A_222.npy\n",
            "A_173.npy\n",
            "A_269.npy\n",
            "A_255.npy\n",
            "A_210.npy\n",
            "A_253.npy\n",
            "A_180.npy\n",
            "A_197.npy\n",
            "A_244.npy\n",
            "A_218.npy\n",
            "A_254.npy\n",
            "A_235.npy\n",
            "A_241.npy\n",
            "A_165.npy\n",
            "A_205.npy\n",
            "A_251.npy\n",
            "A_163.npy\n",
            "A_177.npy\n",
            "A_265.npy\n",
            "A_185.npy\n",
            "A_258.npy\n",
            "A_239.npy\n",
            "A_195.npy\n",
            "A_221.npy\n",
            "A_161.npy\n",
            "A_243.npy\n",
            "A_189.npy\n",
            "A_261.npy\n",
            "A_190.npy\n",
            "A_207.npy\n",
            "A_240.npy\n",
            "A_275.npy\n",
            "A_229.npy\n",
            "A_213.npy\n",
            "A_164.npy\n",
            "A_273.npy\n",
            "A_228.npy\n",
            "A_238.npy\n",
            "A_263.npy\n",
            "A_175.npy\n",
            "A_162.npy\n",
            "A_223.npy\n",
            "A_212.npy\n",
            "A_257.npy\n",
            "A_270.npy\n",
            "A_271.npy\n",
            "A_276.npy\n",
            "A_170.npy\n",
            "A_168.npy\n",
            "A_167.npy\n",
            "A_171.npy\n",
            "A_215.npy\n",
            "A_199.npy\n",
            "A_181.npy\n",
            "A_192.npy\n",
            "A_262.npy\n",
            "A_232.npy\n",
            "A_198.npy\n",
            "A_233.npy\n",
            "A_242.npy\n",
            "A_196.npy\n",
            "A_234.npy\n",
            "A_266.npy\n",
            "A_220.npy\n",
            "A_249.npy\n",
            "A_201.npy\n",
            "A_178.npy\n",
            "A_216.npy\n",
            "A_237.npy\n",
            "A_211.npy\n",
            "A_179.npy\n",
            "A_182.npy\n",
            "A_260.npy\n",
            "A_256.npy\n",
            "A_203.npy\n",
            "A_272.npy\n",
            "A_183.npy\n",
            "A_227.npy\n",
            "A_267.npy\n",
            "A_166.npy\n",
            "A_194.npy\n",
            "A_245.npy\n",
            "A_250.npy\n",
            "A_169.npy\n",
            "A_224.npy\n",
            "A_247.npy\n",
            "A_246.npy\n",
            "A_191.npy\n",
            "A_225.npy\n",
            "A_193.npy\n",
            "A_351.npy\n",
            "A_298.npy\n",
            "A_301.npy\n",
            "A_368.npy\n",
            "A_300.npy\n",
            "A_366.npy\n",
            "A_335.npy\n",
            "A_356.npy\n",
            "A_382.npy\n",
            "A_279.npy\n",
            "A_370.npy\n",
            "A_379.npy\n",
            "A_307.npy\n",
            "A_289.npy\n",
            "A_369.npy\n",
            "A_286.npy\n",
            "A_340.npy\n",
            "A_299.npy\n",
            "A_341.npy\n",
            "A_334.npy\n",
            "A_310.npy\n",
            "A_278.npy\n",
            "A_367.npy\n",
            "A_371.npy\n",
            "A_380.npy\n",
            "A_344.npy\n",
            "A_296.npy\n",
            "A_317.npy\n",
            "A_315.npy\n",
            "A_365.npy\n",
            "A_313.npy\n",
            "A_345.npy\n",
            "A_338.npy\n",
            "A_288.npy\n",
            "A_294.npy\n",
            "A_297.npy\n",
            "A_312.npy\n",
            "A_375.npy\n",
            "A_331.npy\n",
            "A_287.npy\n",
            "A_306.npy\n",
            "A_328.npy\n",
            "A_309.npy\n",
            "A_322.npy\n",
            "A_377.npy\n",
            "A_360.npy\n",
            "A_302.npy\n",
            "A_318.npy\n",
            "A_343.npy\n",
            "A_284.npy\n",
            "A_327.npy\n",
            "A_325.npy\n",
            "A_333.npy\n",
            "A_348.npy\n",
            "A_324.npy\n",
            "A_277.npy\n",
            "A_285.npy\n",
            "A_319.npy\n",
            "A_374.npy\n",
            "A_363.npy\n",
            "A_293.npy\n",
            "A_305.npy\n",
            "A_332.npy\n",
            "A_303.npy\n",
            "A_280.npy\n",
            "A_295.npy\n",
            "A_337.npy\n",
            "A_316.npy\n",
            "A_353.npy\n",
            "A_381.npy\n",
            "A_304.npy\n",
            "A_362.npy\n",
            "A_329.npy\n",
            "A_326.npy\n",
            "A_355.npy\n",
            "A_349.npy\n",
            "A_282.npy\n",
            "A_372.npy\n",
            "A_376.npy\n",
            "A_359.npy\n",
            "A_364.npy\n",
            "A_291.npy\n",
            "A_350.npy\n",
            "A_281.npy\n",
            "A_378.npy\n",
            "A_342.npy\n",
            "A_314.npy\n",
            "A_323.npy\n",
            "A_330.npy\n",
            "A_354.npy\n",
            "A_373.npy\n",
            "A_347.npy\n",
            "A_311.npy\n",
            "A_357.npy\n",
            "A_339.npy\n",
            "A_283.npy\n",
            "A_358.npy\n",
            "A_321.npy\n",
            "A_361.npy\n",
            "A_292.npy\n",
            "A_346.npy\n",
            "A_290.npy\n",
            "A_308.npy\n",
            "A_352.npy\n",
            "A_336.npy\n",
            "A_320.npy\n",
            "C_37.npy\n",
            "C_44.npy\n",
            "C_43.npy\n",
            "A_386.npy\n",
            "C_65.npy\n",
            "C_71.npy\n",
            "C_8.npy\n",
            "C_46.npy\n",
            "C_51.npy\n",
            "C_47.npy\n",
            "C_31.npy\n",
            "C_19.npy\n",
            "A_387.npy\n",
            "C_14.npy\n",
            "C_48.npy\n",
            "C_17.npy\n",
            "C_21.npy\n",
            "C_56.npy\n",
            "C_3.npy\n",
            "C_80.npy\n",
            "A_385.npy\n",
            "C_45.npy\n",
            "C_34.npy\n",
            "C_52.npy\n",
            "A_395.npy\n",
            "A_391.npy\n",
            "C_7.npy\n",
            "A_394.npy\n",
            "C_30.npy\n",
            "C_59.npy\n",
            "C_4.npy\n",
            "C_6.npy\n",
            "C_84.npy\n",
            "C_73.npy\n",
            "C_2.npy\n",
            "C_35.npy\n",
            "C_61.npy\n",
            "C_86.npy\n",
            "C_29.npy\n",
            "C_42.npy\n",
            "C_79.npy\n",
            "C_11.npy\n",
            "C_68.npy\n",
            "C_50.npy\n",
            "A_392.npy\n",
            "C_57.npy\n",
            "C_69.npy\n",
            "C_74.npy\n",
            "C_36.npy\n",
            "C_27.npy\n",
            "C_66.npy\n",
            "C_40.npy\n",
            "C_55.npy\n",
            "C_49.npy\n",
            "C_33.npy\n",
            "C_22.npy\n",
            "C_70.npy\n",
            "A_388.npy\n",
            "C_1.npy\n",
            "C_5.npy\n",
            "C_87.npy\n",
            "C_64.npy\n",
            "C_25.npy\n",
            "C_60.npy\n",
            "C_26.npy\n",
            "C_63.npy\n",
            "C_39.npy\n",
            "C_12.npy\n",
            "C_62.npy\n",
            "C_83.npy\n",
            "A_396.npy\n",
            "A_383.npy\n",
            "A_384.npy\n",
            "A_389.npy\n",
            "C_24.npy\n",
            "C_23.npy\n",
            "C_82.npy\n",
            "A_393.npy\n",
            "C_13.npy\n",
            "A_390.npy\n",
            "C_54.npy\n",
            "C_9.npy\n",
            "C_81.npy\n",
            "C_77.npy\n",
            "C_18.npy\n",
            "C_10.npy\n",
            "C_72.npy\n",
            "C_20.npy\n",
            "C_28.npy\n",
            "C_16.npy\n",
            "C_41.npy\n",
            "C_75.npy\n",
            "C_67.npy\n",
            "C_76.npy\n",
            "C_53.npy\n",
            "C_15.npy\n",
            "C_58.npy\n",
            "C_38.npy\n",
            "C_32.npy\n",
            "C_78.npy\n",
            "C_85.npy\n",
            "C_119.npy\n",
            "C_153.npy\n",
            "C_166.npy\n",
            "C_130.npy\n",
            "C_105.npy\n",
            "C_168.npy\n",
            "C_114.npy\n",
            "C_123.npy\n",
            "C_149.npy\n",
            "C_174.npy\n",
            "C_181.npy\n",
            "C_99.npy\n",
            "C_165.npy\n",
            "C_196.npy\n",
            "C_127.npy\n",
            "C_134.npy\n",
            "C_178.npy\n",
            "C_197.npy\n",
            "C_143.npy\n",
            "C_150.npy\n",
            "C_128.npy\n",
            "C_106.npy\n",
            "C_159.npy\n",
            "C_198.npy\n",
            "C_107.npy\n",
            "C_155.npy\n",
            "C_113.npy\n",
            "C_110.npy\n",
            "C_142.npy\n",
            "C_120.npy\n",
            "C_177.npy\n",
            "C_171.npy\n",
            "C_125.npy\n",
            "C_151.npy\n",
            "C_161.npy\n",
            "C_100.npy\n",
            "C_144.npy\n",
            "C_173.npy\n",
            "C_140.npy\n",
            "C_152.npy\n",
            "C_131.npy\n",
            "C_126.npy\n",
            "C_193.npy\n",
            "C_191.npy\n",
            "C_93.npy\n",
            "C_182.npy\n",
            "C_111.npy\n",
            "C_88.npy\n",
            "C_157.npy\n",
            "C_183.npy\n",
            "C_200.npy\n",
            "C_201.npy\n",
            "C_137.npy\n",
            "C_94.npy\n",
            "C_103.npy\n",
            "C_108.npy\n",
            "C_194.npy\n",
            "C_139.npy\n",
            "C_188.npy\n",
            "C_129.npy\n",
            "C_117.npy\n",
            "C_145.npy\n",
            "C_175.npy\n",
            "C_146.npy\n",
            "C_98.npy\n",
            "C_192.npy\n",
            "C_154.npy\n",
            "C_92.npy\n",
            "C_91.npy\n",
            "C_122.npy\n",
            "C_116.npy\n",
            "C_101.npy\n",
            "C_115.npy\n",
            "C_147.npy\n",
            "C_187.npy\n",
            "C_135.npy\n",
            "C_202.npy\n",
            "C_138.npy\n",
            "C_97.npy\n",
            "C_167.npy\n",
            "C_199.npy\n",
            "C_133.npy\n",
            "C_186.npy\n",
            "C_162.npy\n",
            "C_172.npy\n",
            "C_176.npy\n",
            "C_89.npy\n",
            "C_132.npy\n",
            "C_189.npy\n",
            "C_104.npy\n",
            "C_160.npy\n",
            "C_195.npy\n",
            "C_96.npy\n",
            "C_158.npy\n",
            "C_90.npy\n",
            "C_184.npy\n",
            "C_124.npy\n",
            "C_190.npy\n"
          ]
        }
      ],
      "source": [
        "all_data = []\n",
        "all_labels = []\n",
        "t = np.zeros((500,52))\n",
        "for f in filenames_p:\n",
        "  temp = np.load('./csi_data' + '/' + f)\n",
        "  if(f[0] == 'Z'):\n",
        "    print(f)\n",
        "    data_in = temp\n",
        "    data_in=temp.flatten()\n",
        "    all_data.append(data_in)\n",
        "    all_labels.append(f.split('_')[0])\n",
        "  else:\n",
        "    print(f)\n",
        "    for i in range(500):\n",
        "        t[i]=temp[499-i]\n",
        "    temp=temp.flatten()\n",
        "    t=t.flatten()\n",
        "    all_data.append(temp)\n",
        "    all_labels.append(f.split('_')[0])\n",
        "  temp = np.zeros((500,52))\n",
        "  t = np.zeros((500,52))\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W27TYMFki_xN"
      },
      "outputs": [],
      "source": [
        "# Converting list of arrays to numpy array\n",
        "data_in = np.array(all_data)\n",
        "label_in = np.array(all_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zPuqqJiH-zZp"
      },
      "outputs": [],
      "source": [
        "# Converting labels to numbers\n",
        "label_in[label_in == 'A'] = 0\n",
        "label_in[label_in == 'B'] = 1\n",
        "label_in[label_in == 'C'] = 2\n",
        "label_in[label_in == 'D'] = 3\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItELzJA7_jCN",
        "outputId": "276d77f8-8f02-4910-ae54-4385ebbb36bd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2., 2., 2., ..., 2., 2., 2.])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Converting label array to number type\n",
        "label_in = label_in.astype(np.float64)\n",
        "label_in"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeXyo1mCn8Ar"
      },
      "source": [
        "## Preparing dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IeBHJ8ag_1tD"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Splitting train/test sets with 80:20 ratio and commonly used random state 42\n",
        "train_data, test_data, train_label, test_label = train_test_split(data_in, label_in, test_size=0.20, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nvUXrxtAPrm",
        "outputId": "7996bbdc-2c94-43ad-f8a1-56d87ec58472"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1264, 26000), (1264,)\n",
            "(317, 26000), (317,)\n"
          ]
        }
      ],
      "source": [
        "print(f'{train_data.shape}, {train_label.shape}')\n",
        "print(f'{test_data.shape}, {test_label.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2FpH2dqoKrz"
      },
      "source": [
        "## Plotting function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sADcM_Co9LRi"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhTY3MSALzqX"
      },
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yUe5pcmqQ9y"
      },
      "source": [
        "# Apply data to deep learning models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tl7IWXcPaEb4"
      },
      "source": [
        "## MLP Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0PT4Kp93Bq7"
      },
      "outputs": [],
      "source": [
        "def get_MLP_model(input_dim, learning_rate, num_classes):\n",
        "    InputLayer = tf.keras.layers.InputLayer\n",
        "    Dense = tf.keras.layers.Dense\n",
        "    Flatten = tf.keras.layers.Flatten\n",
        "    LSTM = tf.keras.layers.LSTM\n",
        "\n",
        "    model = tf.keras.Sequential(\n",
        "      [\n",
        "          InputLayer(input_shape=input_dim),\n",
        "          LSTM(1024),\n",
        "          Dense(128, activation=tf.nn.relu),\n",
        "          Dense(num_classes, activation=tf.nn.softmax)\n",
        "      ])\n",
        "    optimizer = tf.keras.optimizers.Adam(\n",
        "        learning_rate=learning_rate)\n",
        "\n",
        "    model.compile(\n",
        "        loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YNWeRl05Wpx",
        "outputId": "47eed254-60f6-43a7-87b9-547f360bbec5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 1024)              4411392   \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 128)               131200    \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 9)                 1161      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,543,753\n",
            "Trainable params: 4,543,753\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "MLP_model = get_MLP_model(train_data[0].shape, 0.001, len(np.unique(train_label)))\n",
        "MLP_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "grFvrI_l2D4T"
      },
      "outputs": [],
      "source": [
        "# Creating checkpoint callback for loading best weights\n",
        "checkpoint_filepath = './MLP_checkpoint'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hbvykBLnqbIM",
        "outputId": "e3d307a9-e6af-44f9-d2c8-467f0ffaf935"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "18/18 [==============================] - 72s 617ms/step - loss: 2.1877 - accuracy: 0.1268 - val_loss: 2.1770 - val_accuracy: 0.0978\n",
            "Epoch 2/200\n",
            "18/18 [==============================] - 11s 595ms/step - loss: 2.2314 - accuracy: 0.1341 - val_loss: 2.1893 - val_accuracy: 0.0960\n",
            "Epoch 3/200\n",
            "18/18 [==============================] - 11s 627ms/step - loss: 2.1714 - accuracy: 0.1223 - val_loss: 2.1386 - val_accuracy: 0.1395\n",
            "Epoch 4/200\n",
            "18/18 [==============================] - 11s 597ms/step - loss: 2.1401 - accuracy: 0.1486 - val_loss: 2.1714 - val_accuracy: 0.1359\n",
            "Epoch 5/200\n",
            "18/18 [==============================] - 11s 600ms/step - loss: 2.1570 - accuracy: 0.1322 - val_loss: 2.1227 - val_accuracy: 0.1667\n",
            "Epoch 6/200\n",
            "18/18 [==============================] - 11s 606ms/step - loss: 2.1815 - accuracy: 0.1553 - val_loss: 2.1743 - val_accuracy: 0.1014\n",
            "Epoch 7/200\n",
            "18/18 [==============================] - 10s 578ms/step - loss: 2.1647 - accuracy: 0.1526 - val_loss: 2.1569 - val_accuracy: 0.1449\n",
            "Epoch 8/200\n",
            "18/18 [==============================] - 11s 609ms/step - loss: 2.1052 - accuracy: 0.1581 - val_loss: 2.1661 - val_accuracy: 0.1649\n",
            "Epoch 9/200\n",
            "18/18 [==============================] - 10s 585ms/step - loss: 2.3828 - accuracy: 0.1250 - val_loss: 2.1922 - val_accuracy: 0.1178\n",
            "Epoch 10/200\n",
            "18/18 [==============================] - 11s 613ms/step - loss: 2.1777 - accuracy: 0.1191 - val_loss: 2.1796 - val_accuracy: 0.1178\n",
            "Epoch 11/200\n",
            "18/18 [==============================] - 11s 623ms/step - loss: 2.1781 - accuracy: 0.1350 - val_loss: 2.1609 - val_accuracy: 0.1830\n",
            "Epoch 12/200\n",
            "18/18 [==============================] - 11s 614ms/step - loss: 2.1291 - accuracy: 0.1644 - val_loss: 2.1400 - val_accuracy: 0.1449\n",
            "Epoch 13/200\n",
            "18/18 [==============================] - 11s 589ms/step - loss: 2.1039 - accuracy: 0.1617 - val_loss: 2.1502 - val_accuracy: 0.1014\n",
            "Epoch 14/200\n",
            "18/18 [==============================] - 11s 624ms/step - loss: 2.1370 - accuracy: 0.1404 - val_loss: 2.0885 - val_accuracy: 0.1920\n",
            "Epoch 15/200\n",
            "18/18 [==============================] - 11s 623ms/step - loss: 2.0639 - accuracy: 0.1585 - val_loss: 1.9759 - val_accuracy: 0.1957\n",
            "Epoch 16/200\n",
            "18/18 [==============================] - 11s 617ms/step - loss: 2.0100 - accuracy: 0.1716 - val_loss: 2.0685 - val_accuracy: 0.0996\n",
            "Epoch 17/200\n",
            "18/18 [==============================] - 11s 617ms/step - loss: 2.1277 - accuracy: 0.1531 - val_loss: 2.1560 - val_accuracy: 0.1069\n",
            "Epoch 18/200\n",
            "18/18 [==============================] - 11s 615ms/step - loss: 2.1094 - accuracy: 0.1508 - val_loss: 2.0718 - val_accuracy: 0.1957\n",
            "Epoch 19/200\n",
            "18/18 [==============================] - 11s 625ms/step - loss: 2.0060 - accuracy: 0.1857 - val_loss: 1.8964 - val_accuracy: 0.2101\n",
            "Epoch 20/200\n",
            "18/18 [==============================] - 11s 612ms/step - loss: 2.0887 - accuracy: 0.1585 - val_loss: 2.0435 - val_accuracy: 0.1721\n",
            "Epoch 21/200\n",
            "18/18 [==============================] - 11s 588ms/step - loss: 1.9573 - accuracy: 0.1852 - val_loss: 1.8962 - val_accuracy: 0.1957\n",
            "Epoch 22/200\n",
            "18/18 [==============================] - 11s 613ms/step - loss: 2.0873 - accuracy: 0.1612 - val_loss: 2.0794 - val_accuracy: 0.1649\n",
            "Epoch 23/200\n",
            "18/18 [==============================] - 11s 591ms/step - loss: 2.0452 - accuracy: 0.1603 - val_loss: 1.9927 - val_accuracy: 0.1812\n",
            "Epoch 24/200\n",
            "18/18 [==============================] - 11s 614ms/step - loss: 1.9290 - accuracy: 0.1929 - val_loss: 1.8501 - val_accuracy: 0.1957\n",
            "Epoch 25/200\n",
            "18/18 [==============================] - 11s 615ms/step - loss: 2.0180 - accuracy: 0.1798 - val_loss: 2.4952 - val_accuracy: 0.1178\n",
            "Epoch 26/200\n",
            "18/18 [==============================] - 11s 614ms/step - loss: 2.2801 - accuracy: 0.1218 - val_loss: 2.2102 - val_accuracy: 0.0960\n",
            "Epoch 27/200\n",
            "18/18 [==============================] - 11s 591ms/step - loss: 2.1779 - accuracy: 0.1322 - val_loss: 2.1767 - val_accuracy: 0.1178\n",
            "Epoch 28/200\n",
            "18/18 [==============================] - 11s 588ms/step - loss: 2.1628 - accuracy: 0.1639 - val_loss: 2.1522 - val_accuracy: 0.1920\n",
            "Epoch 29/200\n",
            "18/18 [==============================] - 11s 588ms/step - loss: 2.1406 - accuracy: 0.1780 - val_loss: 2.0829 - val_accuracy: 0.0833\n",
            "Epoch 30/200\n",
            "18/18 [==============================] - 11s 616ms/step - loss: 2.0643 - accuracy: 0.1753 - val_loss: 2.0815 - val_accuracy: 0.1703\n",
            "Epoch 31/200\n",
            "18/18 [==============================] - 11s 610ms/step - loss: 2.1143 - accuracy: 0.1549 - val_loss: 2.0328 - val_accuracy: 0.1848\n",
            "Epoch 32/200\n",
            "18/18 [==============================] - 10s 582ms/step - loss: 1.9726 - accuracy: 0.1875 - val_loss: 1.9805 - val_accuracy: 0.1630\n",
            "Epoch 33/200\n",
            "18/18 [==============================] - 10s 584ms/step - loss: 1.9606 - accuracy: 0.1834 - val_loss: 1.8820 - val_accuracy: 0.1884\n",
            "Epoch 34/200\n",
            "18/18 [==============================] - 11s 589ms/step - loss: 1.9053 - accuracy: 0.1947 - val_loss: 1.8854 - val_accuracy: 0.2065\n",
            "Epoch 35/200\n",
            "18/18 [==============================] - 11s 617ms/step - loss: 1.9604 - accuracy: 0.1821 - val_loss: 2.3376 - val_accuracy: 0.1341\n",
            "Epoch 36/200\n",
            "18/18 [==============================] - 11s 615ms/step - loss: 2.3188 - accuracy: 0.1259 - val_loss: 2.1863 - val_accuracy: 0.0978\n",
            "Epoch 37/200\n",
            "12/18 [===================>..........] - ETA: 3s - loss: 2.1530 - accuracy: 0.1868"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-79-14880f8156a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mMLP_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_checkpoint_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1654\u001b[0m                             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1655\u001b[0m                             \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1656\u001b[0;31m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1657\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1658\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"end\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"end\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1094\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1095\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1168\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m             \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1170\u001b[0;31m             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1171\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 665\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m         \u001b[0;31m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0;31m# as-is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1153\u001b[0m     \"\"\"\n\u001b[1;32m   1154\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1155\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1156\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1119\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "MLP_model.fit(train_data, train_label, batch_size=128, epochs=200, validation_split=0.2, shuffle=True, callbacks=[model_checkpoint_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "sCiSylfu8zM0",
        "outputId": "a3ede40c-8d08-4621-8d0c-9d1f2e66d02c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "320/320 - 0s - 431ms/epoch - 1ms/step\n",
            "Confusion matrix, without normalization\n",
            "[[43 30  0 13]\n",
            " [15 41  0 11]\n",
            " [ 0  4 56 15]\n",
            " [13 12  3 64]]\n",
            "Per class:  [0.5        0.6119403  0.74666667 0.69565217]\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "predictions = MLP_model.predict(\n",
        "      x=test_data\n",
        "    , batch_size=1\n",
        "    , verbose=2\n",
        ")\n",
        "\n",
        "# Rounding predictions values to map into confusion matrix\n",
        "rounded_predictions = np.argmax(predictions, axis=-1)\n",
        "\n",
        "cm_plot_labels = ['A', 'B', 'C', 'D']\n",
        "cm = confusion_matrix(y_true=test_label, y_pred=rounded_predictions)\n",
        "accuracy = accuracy_score(test_label, rounded_predictions) * 100\n",
        "plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title=f'Confusion Matrix: MLP. Accuracy {accuracy:.02f}%')\n",
        "print(\"Per class: \", cm.diagonal()/cm.sum(axis=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYluQlZPaOEQ"
      },
      "source": [
        "## LeNet Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EwgjRwHs5-lV"
      },
      "outputs": [],
      "source": [
        "def get_LeNet_model(input_dim, learning_rate, num_classes):\n",
        "    InputLayer = tf.keras.layers.InputLayer\n",
        "    Conv1D = tf.keras.layers.Conv1D\n",
        "    Dense = tf.keras.layers.Dense\n",
        "    Flatten = tf.keras.layers.Flatten\n",
        "    MaxPool2D = tf.keras.layers.MaxPool1D\n",
        "\n",
        "    model = tf.keras.Sequential(\n",
        "      [\n",
        "          InputLayer(input_shape=input_dim),\n",
        "          Conv1D(32, kernel_size=7, strides=1, activation='relu'),\n",
        "          MaxPool2D(pool_size=2),\n",
        "          Conv1D(64, kernel_size=4, strides=1, padding='same', activation='relu'),\n",
        "          MaxPool2D(pool_size=2),\n",
        "          Conv1D(96, kernel_size=3, strides=1, activation='relu'),\n",
        "          MaxPool2D(pool_size=2),\n",
        "          Flatten(),\n",
        "          Dense(128, activation=tf.nn.relu),\n",
        "          Dense(num_classes, activation=tf.nn.softmax)\n",
        "      ])\n",
        "    optimizer = tf.keras.optimizers.Adam(\n",
        "        learning_rate=learning_rate)\n",
        "\n",
        "    model.compile(\n",
        "        loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vv9IXtjruQSk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69388501-edcf-451e-dcf8-864f3b6cae87"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1264, 26000, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# Expanding dataset dimensions since CNN2D takes in 3 dimensions: HWC\n",
        "train_data2 = train_data.copy()\n",
        "train_data2 = np.expand_dims(train_data2, axis=-1)\n",
        "train_data2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YYe6GpluaZq1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f28bda06-20e2-458c-a6ce-b1136038b50d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 25994, 32)         256       \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 12997, 32)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 12997, 64)         8256      \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 6498, 64)         0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 6496, 96)          18528     \n",
            "                                                                 \n",
            " max_pooling1d_2 (MaxPooling  (None, 3248, 96)         0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 311808)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               39911552  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4)                 516       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 39,939,108\n",
            "Trainable params: 39,939,108\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "LeNet_model = get_LeNet_model(train_data2[0].shape, 0.001, len(np.unique(train_label)))\n",
        "LeNet_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hzaIP0A6aepg"
      },
      "outputs": [],
      "source": [
        "LeNet_checkpoint_filepath = './LeNet_checkpoint'\n",
        "LeNet_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=LeNet_checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mfqBgtNSamn7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63ae95e5-e6da-47d2-b82e-8374babac3c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "8/8 [==============================] - 22s 1s/step - loss: 2.0533 - accuracy: 0.2591 - val_loss: 1.3952 - val_accuracy: 0.2688\n",
            "Epoch 2/200\n",
            "8/8 [==============================] - 4s 565ms/step - loss: 1.3741 - accuracy: 0.3086 - val_loss: 1.3605 - val_accuracy: 0.3360\n",
            "Epoch 3/200\n",
            "8/8 [==============================] - 4s 547ms/step - loss: 1.3122 - accuracy: 0.4530 - val_loss: 1.2540 - val_accuracy: 0.3636\n",
            "Epoch 4/200\n",
            "8/8 [==============================] - 4s 591ms/step - loss: 1.1560 - accuracy: 0.5470 - val_loss: 1.0390 - val_accuracy: 0.6285\n",
            "Epoch 5/200\n",
            "8/8 [==============================] - 4s 553ms/step - loss: 0.8408 - accuracy: 0.7883 - val_loss: 0.6383 - val_accuracy: 0.8735\n",
            "Epoch 6/200\n",
            "8/8 [==============================] - 2s 254ms/step - loss: 0.5259 - accuracy: 0.8595 - val_loss: 0.5008 - val_accuracy: 0.8419\n",
            "Epoch 7/200\n",
            "8/8 [==============================] - 2s 253ms/step - loss: 0.3582 - accuracy: 0.8853 - val_loss: 0.3953 - val_accuracy: 0.8735\n",
            "Epoch 8/200\n",
            "8/8 [==============================] - 4s 580ms/step - loss: 0.2963 - accuracy: 0.9021 - val_loss: 0.3744 - val_accuracy: 0.9012\n",
            "Epoch 9/200\n",
            "8/8 [==============================] - 4s 540ms/step - loss: 0.2800 - accuracy: 0.9090 - val_loss: 0.3186 - val_accuracy: 0.9051\n",
            "Epoch 10/200\n",
            "8/8 [==============================] - 4s 538ms/step - loss: 0.2648 - accuracy: 0.9189 - val_loss: 0.3088 - val_accuracy: 0.9249\n",
            "Epoch 11/200\n",
            "8/8 [==============================] - 4s 580ms/step - loss: 0.2000 - accuracy: 0.9327 - val_loss: 0.2557 - val_accuracy: 0.9368\n",
            "Epoch 12/200\n",
            "8/8 [==============================] - 4s 560ms/step - loss: 0.1527 - accuracy: 0.9575 - val_loss: 0.2240 - val_accuracy: 0.9486\n",
            "Epoch 13/200\n",
            "8/8 [==============================] - 2s 254ms/step - loss: 0.1341 - accuracy: 0.9594 - val_loss: 0.2251 - val_accuracy: 0.9368\n",
            "Epoch 14/200\n",
            "8/8 [==============================] - 4s 537ms/step - loss: 0.1282 - accuracy: 0.9624 - val_loss: 0.1857 - val_accuracy: 0.9565\n",
            "Epoch 15/200\n",
            "8/8 [==============================] - 4s 578ms/step - loss: 0.0982 - accuracy: 0.9683 - val_loss: 0.1622 - val_accuracy: 0.9605\n",
            "Epoch 16/200\n",
            "8/8 [==============================] - 2s 257ms/step - loss: 0.0773 - accuracy: 0.9763 - val_loss: 0.2004 - val_accuracy: 0.9526\n",
            "Epoch 17/200\n",
            "8/8 [==============================] - 2s 273ms/step - loss: 0.0762 - accuracy: 0.9723 - val_loss: 0.1617 - val_accuracy: 0.9486\n",
            "Epoch 18/200\n",
            "8/8 [==============================] - 2s 256ms/step - loss: 0.0635 - accuracy: 0.9792 - val_loss: 0.2044 - val_accuracy: 0.9447\n",
            "Epoch 19/200\n",
            "8/8 [==============================] - 2s 256ms/step - loss: 0.1149 - accuracy: 0.9594 - val_loss: 0.1782 - val_accuracy: 0.9565\n",
            "Epoch 20/200\n",
            "8/8 [==============================] - 2s 262ms/step - loss: 0.1167 - accuracy: 0.9634 - val_loss: 0.1913 - val_accuracy: 0.9486\n",
            "Epoch 21/200\n",
            "8/8 [==============================] - 4s 565ms/step - loss: 0.0779 - accuracy: 0.9743 - val_loss: 0.1462 - val_accuracy: 0.9684\n",
            "Epoch 22/200\n",
            "8/8 [==============================] - 2s 256ms/step - loss: 0.0569 - accuracy: 0.9832 - val_loss: 0.1464 - val_accuracy: 0.9565\n",
            "Epoch 23/200\n",
            "8/8 [==============================] - 2s 273ms/step - loss: 0.0465 - accuracy: 0.9832 - val_loss: 0.1643 - val_accuracy: 0.9644\n",
            "Epoch 24/200\n",
            "8/8 [==============================] - 2s 256ms/step - loss: 0.0368 - accuracy: 0.9901 - val_loss: 0.1983 - val_accuracy: 0.9526\n",
            "Epoch 25/200\n",
            "8/8 [==============================] - 2s 280ms/step - loss: 0.0483 - accuracy: 0.9862 - val_loss: 0.1641 - val_accuracy: 0.9684\n",
            "Epoch 26/200\n",
            "8/8 [==============================] - 2s 294ms/step - loss: 0.0394 - accuracy: 0.9881 - val_loss: 0.1834 - val_accuracy: 0.9605\n",
            "Epoch 27/200\n",
            "8/8 [==============================] - 2s 258ms/step - loss: 0.0529 - accuracy: 0.9822 - val_loss: 0.1955 - val_accuracy: 0.9526\n",
            "Epoch 28/200\n",
            "8/8 [==============================] - 2s 255ms/step - loss: 0.0896 - accuracy: 0.9733 - val_loss: 0.1801 - val_accuracy: 0.9644\n",
            "Epoch 29/200\n",
            "8/8 [==============================] - 2s 274ms/step - loss: 0.0784 - accuracy: 0.9733 - val_loss: 0.1747 - val_accuracy: 0.9565\n",
            "Epoch 30/200\n",
            "8/8 [==============================] - 2s 258ms/step - loss: 0.0784 - accuracy: 0.9792 - val_loss: 0.1821 - val_accuracy: 0.9526\n",
            "Epoch 31/200\n",
            "8/8 [==============================] - 2s 275ms/step - loss: 0.0580 - accuracy: 0.9842 - val_loss: 0.1709 - val_accuracy: 0.9644\n",
            "Epoch 32/200\n",
            "8/8 [==============================] - 2s 264ms/step - loss: 0.0446 - accuracy: 0.9862 - val_loss: 0.1556 - val_accuracy: 0.9644\n",
            "Epoch 33/200\n",
            "8/8 [==============================] - 4s 550ms/step - loss: 0.0314 - accuracy: 0.9931 - val_loss: 0.1522 - val_accuracy: 0.9723\n",
            "Epoch 34/200\n",
            "8/8 [==============================] - 2s 257ms/step - loss: 0.0238 - accuracy: 0.9941 - val_loss: 0.1722 - val_accuracy: 0.9605\n",
            "Epoch 35/200\n",
            "8/8 [==============================] - 2s 258ms/step - loss: 0.0196 - accuracy: 0.9921 - val_loss: 0.2052 - val_accuracy: 0.9605\n",
            "Epoch 36/200\n",
            "8/8 [==============================] - 2s 275ms/step - loss: 0.0218 - accuracy: 0.9921 - val_loss: 0.1942 - val_accuracy: 0.9684\n",
            "Epoch 37/200\n",
            "8/8 [==============================] - 2s 260ms/step - loss: 0.0168 - accuracy: 0.9941 - val_loss: 0.1738 - val_accuracy: 0.9644\n",
            "Epoch 38/200\n",
            "8/8 [==============================] - 2s 264ms/step - loss: 0.0208 - accuracy: 0.9951 - val_loss: 0.2006 - val_accuracy: 0.9486\n",
            "Epoch 39/200\n",
            "8/8 [==============================] - 2s 277ms/step - loss: 0.0188 - accuracy: 0.9960 - val_loss: 0.1801 - val_accuracy: 0.9605\n",
            "Epoch 40/200\n",
            "8/8 [==============================] - 2s 258ms/step - loss: 0.0136 - accuracy: 0.9970 - val_loss: 0.1928 - val_accuracy: 0.9644\n",
            "Epoch 41/200\n",
            "8/8 [==============================] - 2s 258ms/step - loss: 0.0129 - accuracy: 0.9960 - val_loss: 0.1982 - val_accuracy: 0.9565\n",
            "Epoch 42/200\n",
            "8/8 [==============================] - 2s 257ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.2202 - val_accuracy: 0.9565\n",
            "Epoch 43/200\n",
            "8/8 [==============================] - 2s 258ms/step - loss: 0.0077 - accuracy: 0.9990 - val_loss: 0.2134 - val_accuracy: 0.9684\n",
            "Epoch 44/200\n",
            "8/8 [==============================] - 2s 263ms/step - loss: 0.0088 - accuracy: 0.9980 - val_loss: 0.2240 - val_accuracy: 0.9605\n",
            "Epoch 45/200\n",
            "8/8 [==============================] - 2s 282ms/step - loss: 0.0063 - accuracy: 0.9990 - val_loss: 0.2176 - val_accuracy: 0.9684\n",
            "Epoch 46/200\n",
            "8/8 [==============================] - 2s 275ms/step - loss: 0.0046 - accuracy: 0.9990 - val_loss: 0.2285 - val_accuracy: 0.9644\n",
            "Epoch 47/200\n",
            "8/8 [==============================] - 2s 275ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.2323 - val_accuracy: 0.9644\n",
            "Epoch 48/200\n",
            "8/8 [==============================] - 2s 259ms/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.2487 - val_accuracy: 0.9605\n",
            "Epoch 49/200\n",
            "8/8 [==============================] - 2s 257ms/step - loss: 0.0051 - accuracy: 0.9980 - val_loss: 0.2450 - val_accuracy: 0.9605\n",
            "Epoch 50/200\n",
            "8/8 [==============================] - 2s 278ms/step - loss: 0.0047 - accuracy: 0.9980 - val_loss: 0.2555 - val_accuracy: 0.9684\n",
            "Epoch 51/200\n",
            "8/8 [==============================] - 2s 283ms/step - loss: 0.0051 - accuracy: 0.9990 - val_loss: 0.2388 - val_accuracy: 0.9644\n",
            "Epoch 52/200\n",
            "8/8 [==============================] - 2s 276ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2461 - val_accuracy: 0.9644\n",
            "Epoch 53/200\n",
            "8/8 [==============================] - 2s 276ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2305 - val_accuracy: 0.9644\n",
            "Epoch 54/200\n",
            "8/8 [==============================] - 2s 258ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2355 - val_accuracy: 0.9644\n",
            "Epoch 55/200\n",
            "8/8 [==============================] - 2s 258ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2467 - val_accuracy: 0.9644\n",
            "Epoch 56/200\n",
            "8/8 [==============================] - 2s 258ms/step - loss: 9.9581e-04 - accuracy: 1.0000 - val_loss: 0.2530 - val_accuracy: 0.9644\n",
            "Epoch 57/200\n",
            "8/8 [==============================] - 2s 265ms/step - loss: 9.4940e-04 - accuracy: 1.0000 - val_loss: 0.2540 - val_accuracy: 0.9644\n",
            "Epoch 58/200\n",
            "8/8 [==============================] - 2s 261ms/step - loss: 8.3821e-04 - accuracy: 1.0000 - val_loss: 0.2577 - val_accuracy: 0.9644\n",
            "Epoch 59/200\n",
            "8/8 [==============================] - 2s 277ms/step - loss: 7.8674e-04 - accuracy: 1.0000 - val_loss: 0.2606 - val_accuracy: 0.9644\n",
            "Epoch 60/200\n",
            "8/8 [==============================] - 2s 276ms/step - loss: 7.4442e-04 - accuracy: 1.0000 - val_loss: 0.2662 - val_accuracy: 0.9644\n",
            "Epoch 61/200\n",
            "8/8 [==============================] - 2s 259ms/step - loss: 6.9546e-04 - accuracy: 1.0000 - val_loss: 0.2679 - val_accuracy: 0.9644\n",
            "Epoch 62/200\n",
            "8/8 [==============================] - 2s 276ms/step - loss: 6.8155e-04 - accuracy: 1.0000 - val_loss: 0.2701 - val_accuracy: 0.9644\n",
            "Epoch 63/200\n",
            "8/8 [==============================] - 2s 268ms/step - loss: 6.1018e-04 - accuracy: 1.0000 - val_loss: 0.2748 - val_accuracy: 0.9644\n",
            "Epoch 64/200\n",
            "8/8 [==============================] - 2s 285ms/step - loss: 5.8906e-04 - accuracy: 1.0000 - val_loss: 0.2774 - val_accuracy: 0.9644\n",
            "Epoch 65/200\n",
            "8/8 [==============================] - 2s 276ms/step - loss: 6.2833e-04 - accuracy: 1.0000 - val_loss: 0.2773 - val_accuracy: 0.9644\n",
            "Epoch 66/200\n",
            "8/8 [==============================] - 2s 277ms/step - loss: 5.6694e-04 - accuracy: 1.0000 - val_loss: 0.2825 - val_accuracy: 0.9684\n",
            "Epoch 67/200\n",
            "8/8 [==============================] - 2s 261ms/step - loss: 5.0481e-04 - accuracy: 1.0000 - val_loss: 0.2837 - val_accuracy: 0.9644\n",
            "Epoch 68/200\n",
            "8/8 [==============================] - 2s 260ms/step - loss: 4.6629e-04 - accuracy: 1.0000 - val_loss: 0.2846 - val_accuracy: 0.9644\n",
            "Epoch 69/200\n",
            "8/8 [==============================] - 2s 263ms/step - loss: 4.4671e-04 - accuracy: 1.0000 - val_loss: 0.2876 - val_accuracy: 0.9644\n",
            "Epoch 70/200\n",
            "8/8 [==============================] - 2s 282ms/step - loss: 4.2832e-04 - accuracy: 1.0000 - val_loss: 0.2890 - val_accuracy: 0.9644\n",
            "Epoch 71/200\n",
            "8/8 [==============================] - 2s 260ms/step - loss: 4.1848e-04 - accuracy: 1.0000 - val_loss: 0.2925 - val_accuracy: 0.9644\n",
            "Epoch 72/200\n",
            "8/8 [==============================] - 2s 260ms/step - loss: 3.9657e-04 - accuracy: 1.0000 - val_loss: 0.2907 - val_accuracy: 0.9644\n",
            "Epoch 73/200\n",
            "8/8 [==============================] - 2s 278ms/step - loss: 3.7272e-04 - accuracy: 1.0000 - val_loss: 0.2926 - val_accuracy: 0.9644\n",
            "Epoch 74/200\n",
            "8/8 [==============================] - 2s 277ms/step - loss: 3.6102e-04 - accuracy: 1.0000 - val_loss: 0.2921 - val_accuracy: 0.9644\n",
            "Epoch 75/200\n",
            "8/8 [==============================] - 2s 261ms/step - loss: 3.3499e-04 - accuracy: 1.0000 - val_loss: 0.2953 - val_accuracy: 0.9644\n",
            "Epoch 76/200\n",
            "8/8 [==============================] - 2s 270ms/step - loss: 3.1876e-04 - accuracy: 1.0000 - val_loss: 0.2978 - val_accuracy: 0.9644\n",
            "Epoch 77/200\n",
            "8/8 [==============================] - 2s 280ms/step - loss: 3.0622e-04 - accuracy: 1.0000 - val_loss: 0.2989 - val_accuracy: 0.9644\n",
            "Epoch 78/200\n",
            "8/8 [==============================] - 2s 262ms/step - loss: 2.9105e-04 - accuracy: 1.0000 - val_loss: 0.3008 - val_accuracy: 0.9644\n",
            "Epoch 79/200\n",
            "8/8 [==============================] - 2s 260ms/step - loss: 2.7445e-04 - accuracy: 1.0000 - val_loss: 0.3021 - val_accuracy: 0.9644\n",
            "Epoch 80/200\n",
            "8/8 [==============================] - 2s 278ms/step - loss: 2.6214e-04 - accuracy: 1.0000 - val_loss: 0.3038 - val_accuracy: 0.9644\n",
            "Epoch 81/200\n",
            "8/8 [==============================] - 2s 278ms/step - loss: 2.5094e-04 - accuracy: 1.0000 - val_loss: 0.3064 - val_accuracy: 0.9644\n",
            "Epoch 82/200\n",
            "8/8 [==============================] - 2s 281ms/step - loss: 2.4486e-04 - accuracy: 1.0000 - val_loss: 0.3061 - val_accuracy: 0.9644\n",
            "Epoch 83/200\n",
            "8/8 [==============================] - 2s 264ms/step - loss: 2.3393e-04 - accuracy: 1.0000 - val_loss: 0.3092 - val_accuracy: 0.9644\n",
            "Epoch 84/200\n",
            "8/8 [==============================] - 2s 261ms/step - loss: 2.2764e-04 - accuracy: 1.0000 - val_loss: 0.3104 - val_accuracy: 0.9644\n",
            "Epoch 85/200\n",
            "8/8 [==============================] - 2s 262ms/step - loss: 2.1627e-04 - accuracy: 1.0000 - val_loss: 0.3097 - val_accuracy: 0.9644\n",
            "Epoch 86/200\n",
            "8/8 [==============================] - 2s 259ms/step - loss: 2.1010e-04 - accuracy: 1.0000 - val_loss: 0.3129 - val_accuracy: 0.9644\n",
            "Epoch 87/200\n",
            "8/8 [==============================] - 2s 277ms/step - loss: 1.9750e-04 - accuracy: 1.0000 - val_loss: 0.3128 - val_accuracy: 0.9644\n",
            "Epoch 88/200\n",
            "8/8 [==============================] - 2s 263ms/step - loss: 1.8703e-04 - accuracy: 1.0000 - val_loss: 0.3152 - val_accuracy: 0.9644\n",
            "Epoch 89/200\n",
            "8/8 [==============================] - 2s 284ms/step - loss: 1.8415e-04 - accuracy: 1.0000 - val_loss: 0.3178 - val_accuracy: 0.9644\n",
            "Epoch 90/200\n",
            "8/8 [==============================] - 2s 279ms/step - loss: 1.7383e-04 - accuracy: 1.0000 - val_loss: 0.3181 - val_accuracy: 0.9644\n",
            "Epoch 91/200\n",
            "8/8 [==============================] - 2s 260ms/step - loss: 1.6598e-04 - accuracy: 1.0000 - val_loss: 0.3191 - val_accuracy: 0.9644\n",
            "Epoch 92/200\n",
            "8/8 [==============================] - 2s 259ms/step - loss: 1.6171e-04 - accuracy: 1.0000 - val_loss: 0.3212 - val_accuracy: 0.9644\n",
            "Epoch 93/200\n",
            "8/8 [==============================] - 2s 260ms/step - loss: 1.5440e-04 - accuracy: 1.0000 - val_loss: 0.3229 - val_accuracy: 0.9644\n",
            "Epoch 94/200\n",
            "8/8 [==============================] - 2s 262ms/step - loss: 1.4975e-04 - accuracy: 1.0000 - val_loss: 0.3252 - val_accuracy: 0.9644\n",
            "Epoch 95/200\n",
            "8/8 [==============================] - 2s 286ms/step - loss: 1.4253e-04 - accuracy: 1.0000 - val_loss: 0.3276 - val_accuracy: 0.9644\n",
            "Epoch 96/200\n",
            "8/8 [==============================] - 2s 264ms/step - loss: 1.3986e-04 - accuracy: 1.0000 - val_loss: 0.3282 - val_accuracy: 0.9644\n",
            "Epoch 97/200\n",
            "8/8 [==============================] - 2s 260ms/step - loss: 1.3365e-04 - accuracy: 1.0000 - val_loss: 0.3310 - val_accuracy: 0.9644\n",
            "Epoch 98/200\n",
            "8/8 [==============================] - 2s 278ms/step - loss: 1.3625e-04 - accuracy: 1.0000 - val_loss: 0.3311 - val_accuracy: 0.9644\n",
            "Epoch 99/200\n",
            "8/8 [==============================] - 2s 260ms/step - loss: 1.2537e-04 - accuracy: 1.0000 - val_loss: 0.3334 - val_accuracy: 0.9644\n",
            "Epoch 100/200\n",
            "8/8 [==============================] - 2s 261ms/step - loss: 1.2048e-04 - accuracy: 1.0000 - val_loss: 0.3338 - val_accuracy: 0.9644\n",
            "Epoch 101/200\n",
            "8/8 [==============================] - 2s 283ms/step - loss: 1.1868e-04 - accuracy: 1.0000 - val_loss: 0.3375 - val_accuracy: 0.9644\n",
            "Epoch 102/200\n",
            "8/8 [==============================] - 2s 283ms/step - loss: 1.1323e-04 - accuracy: 1.0000 - val_loss: 0.3373 - val_accuracy: 0.9644\n",
            "Epoch 103/200\n",
            "8/8 [==============================] - 2s 263ms/step - loss: 1.0988e-04 - accuracy: 1.0000 - val_loss: 0.3395 - val_accuracy: 0.9644\n",
            "Epoch 104/200\n",
            "8/8 [==============================] - 2s 278ms/step - loss: 1.0573e-04 - accuracy: 1.0000 - val_loss: 0.3408 - val_accuracy: 0.9644\n",
            "Epoch 105/200\n",
            "8/8 [==============================] - 2s 261ms/step - loss: 1.0284e-04 - accuracy: 1.0000 - val_loss: 0.3424 - val_accuracy: 0.9644\n",
            "Epoch 106/200\n",
            "8/8 [==============================] - 2s 278ms/step - loss: 1.0175e-04 - accuracy: 1.0000 - val_loss: 0.3449 - val_accuracy: 0.9644\n",
            "Epoch 107/200\n",
            "8/8 [==============================] - 2s 264ms/step - loss: 9.8301e-05 - accuracy: 1.0000 - val_loss: 0.3448 - val_accuracy: 0.9644\n",
            "Epoch 108/200\n",
            "8/8 [==============================] - 2s 281ms/step - loss: 9.4646e-05 - accuracy: 1.0000 - val_loss: 0.3483 - val_accuracy: 0.9644\n",
            "Epoch 109/200\n",
            "8/8 [==============================] - 2s 261ms/step - loss: 9.1655e-05 - accuracy: 1.0000 - val_loss: 0.3481 - val_accuracy: 0.9644\n",
            "Epoch 110/200\n",
            "8/8 [==============================] - 2s 259ms/step - loss: 9.0198e-05 - accuracy: 1.0000 - val_loss: 0.3510 - val_accuracy: 0.9644\n",
            "Epoch 111/200\n",
            "8/8 [==============================] - 2s 260ms/step - loss: 8.8824e-05 - accuracy: 1.0000 - val_loss: 0.3475 - val_accuracy: 0.9644\n",
            "Epoch 112/200\n",
            "8/8 [==============================] - 2s 260ms/step - loss: 9.7034e-05 - accuracy: 1.0000 - val_loss: 0.3488 - val_accuracy: 0.9644\n",
            "Epoch 113/200\n",
            "8/8 [==============================] - 2s 262ms/step - loss: 8.8176e-05 - accuracy: 1.0000 - val_loss: 0.3532 - val_accuracy: 0.9644\n",
            "Epoch 114/200\n",
            "8/8 [==============================] - 2s 268ms/step - loss: 8.3144e-05 - accuracy: 1.0000 - val_loss: 0.3484 - val_accuracy: 0.9644\n",
            "Epoch 115/200\n",
            "8/8 [==============================] - 2s 262ms/step - loss: 8.6026e-05 - accuracy: 1.0000 - val_loss: 0.3537 - val_accuracy: 0.9684\n",
            "Epoch 116/200\n",
            "8/8 [==============================] - 2s 260ms/step - loss: 7.6382e-05 - accuracy: 1.0000 - val_loss: 0.3524 - val_accuracy: 0.9644\n",
            "Epoch 117/200\n",
            "8/8 [==============================] - 2s 279ms/step - loss: 7.5393e-05 - accuracy: 1.0000 - val_loss: 0.3557 - val_accuracy: 0.9684\n",
            "Epoch 118/200\n",
            "8/8 [==============================] - 2s 261ms/step - loss: 7.1971e-05 - accuracy: 1.0000 - val_loss: 0.3555 - val_accuracy: 0.9644\n",
            "Epoch 119/200\n",
            "8/8 [==============================] - 2s 260ms/step - loss: 6.9446e-05 - accuracy: 1.0000 - val_loss: 0.3580 - val_accuracy: 0.9644\n",
            "Epoch 120/200\n",
            "8/8 [==============================] - 2s 282ms/step - loss: 6.8552e-05 - accuracy: 1.0000 - val_loss: 0.3598 - val_accuracy: 0.9684\n",
            "Epoch 121/200\n",
            "8/8 [==============================] - 2s 281ms/step - loss: 6.6401e-05 - accuracy: 1.0000 - val_loss: 0.3607 - val_accuracy: 0.9644\n",
            "Epoch 122/200\n",
            "8/8 [==============================] - 2s 262ms/step - loss: 6.3920e-05 - accuracy: 1.0000 - val_loss: 0.3628 - val_accuracy: 0.9684\n",
            "Epoch 123/200\n",
            "8/8 [==============================] - 2s 262ms/step - loss: 6.2752e-05 - accuracy: 1.0000 - val_loss: 0.3633 - val_accuracy: 0.9684\n",
            "Epoch 124/200\n",
            "8/8 [==============================] - 2s 260ms/step - loss: 6.0759e-05 - accuracy: 1.0000 - val_loss: 0.3649 - val_accuracy: 0.9684\n",
            "Epoch 125/200\n",
            "8/8 [==============================] - 2s 278ms/step - loss: 5.9969e-05 - accuracy: 1.0000 - val_loss: 0.3655 - val_accuracy: 0.9644\n",
            "Epoch 126/200\n",
            "8/8 [==============================] - 2s 281ms/step - loss: 5.8618e-05 - accuracy: 1.0000 - val_loss: 0.3678 - val_accuracy: 0.9684\n",
            "Epoch 127/200\n",
            "8/8 [==============================] - 2s 265ms/step - loss: 5.7738e-05 - accuracy: 1.0000 - val_loss: 0.3685 - val_accuracy: 0.9684\n",
            "Epoch 128/200\n",
            "8/8 [==============================] - 2s 278ms/step - loss: 5.6407e-05 - accuracy: 1.0000 - val_loss: 0.3684 - val_accuracy: 0.9684\n",
            "Epoch 129/200\n",
            "8/8 [==============================] - 2s 260ms/step - loss: 5.4742e-05 - accuracy: 1.0000 - val_loss: 0.3689 - val_accuracy: 0.9684\n",
            "Epoch 130/200\n",
            "8/8 [==============================] - 2s 260ms/step - loss: 5.3630e-05 - accuracy: 1.0000 - val_loss: 0.3715 - val_accuracy: 0.9684\n",
            "Epoch 131/200\n",
            "8/8 [==============================] - 2s 261ms/step - loss: 5.2716e-05 - accuracy: 1.0000 - val_loss: 0.3707 - val_accuracy: 0.9684\n",
            "Epoch 132/200\n",
            "8/8 [==============================] - 2s 260ms/step - loss: 5.0451e-05 - accuracy: 1.0000 - val_loss: 0.3725 - val_accuracy: 0.9684\n",
            "Epoch 133/200\n",
            "8/8 [==============================] - 2s 265ms/step - loss: 4.9341e-05 - accuracy: 1.0000 - val_loss: 0.3731 - val_accuracy: 0.9684\n",
            "Epoch 134/200\n",
            "8/8 [==============================] - 2s 263ms/step - loss: 4.8454e-05 - accuracy: 1.0000 - val_loss: 0.3747 - val_accuracy: 0.9684\n",
            "Epoch 135/200\n",
            "8/8 [==============================] - 2s 278ms/step - loss: 4.7484e-05 - accuracy: 1.0000 - val_loss: 0.3752 - val_accuracy: 0.9684\n",
            "Epoch 136/200\n",
            "8/8 [==============================] - 2s 260ms/step - loss: 4.5782e-05 - accuracy: 1.0000 - val_loss: 0.3761 - val_accuracy: 0.9684\n",
            "Epoch 137/200\n",
            "8/8 [==============================] - 2s 261ms/step - loss: 4.5444e-05 - accuracy: 1.0000 - val_loss: 0.3779 - val_accuracy: 0.9684\n",
            "Epoch 138/200\n",
            "8/8 [==============================] - 2s 279ms/step - loss: 4.4701e-05 - accuracy: 1.0000 - val_loss: 0.3778 - val_accuracy: 0.9684\n",
            "Epoch 139/200\n",
            "8/8 [==============================] - 2s 284ms/step - loss: 4.4586e-05 - accuracy: 1.0000 - val_loss: 0.3788 - val_accuracy: 0.9684\n",
            "Epoch 140/200\n",
            "8/8 [==============================] - 2s 265ms/step - loss: 4.3588e-05 - accuracy: 1.0000 - val_loss: 0.3805 - val_accuracy: 0.9684\n",
            "Epoch 141/200\n",
            "8/8 [==============================] - 2s 261ms/step - loss: 4.2208e-05 - accuracy: 1.0000 - val_loss: 0.3792 - val_accuracy: 0.9644\n",
            "Epoch 142/200\n",
            "8/8 [==============================] - 2s 262ms/step - loss: 4.2104e-05 - accuracy: 1.0000 - val_loss: 0.3826 - val_accuracy: 0.9684\n",
            "Epoch 143/200\n",
            "8/8 [==============================] - 2s 263ms/step - loss: 4.1390e-05 - accuracy: 1.0000 - val_loss: 0.3797 - val_accuracy: 0.9644\n",
            "Epoch 144/200\n",
            "8/8 [==============================] - 2s 263ms/step - loss: 3.9281e-05 - accuracy: 1.0000 - val_loss: 0.3833 - val_accuracy: 0.9684\n",
            "Epoch 145/200\n",
            "8/8 [==============================] - 2s 281ms/step - loss: 3.8282e-05 - accuracy: 1.0000 - val_loss: 0.3819 - val_accuracy: 0.9644\n",
            "Epoch 146/200\n",
            "8/8 [==============================] - 2s 266ms/step - loss: 3.8349e-05 - accuracy: 1.0000 - val_loss: 0.3843 - val_accuracy: 0.9644\n",
            "Epoch 147/200\n",
            "8/8 [==============================] - 2s 262ms/step - loss: 3.6835e-05 - accuracy: 1.0000 - val_loss: 0.3840 - val_accuracy: 0.9684\n",
            "Epoch 148/200\n",
            "8/8 [==============================] - 2s 261ms/step - loss: 3.5859e-05 - accuracy: 1.0000 - val_loss: 0.3863 - val_accuracy: 0.9644\n",
            "Epoch 149/200\n",
            "8/8 [==============================] - 2s 278ms/step - loss: 3.5461e-05 - accuracy: 1.0000 - val_loss: 0.3871 - val_accuracy: 0.9644\n",
            "Epoch 150/200\n",
            "8/8 [==============================] - 2s 262ms/step - loss: 3.4661e-05 - accuracy: 1.0000 - val_loss: 0.3878 - val_accuracy: 0.9644\n",
            "Epoch 151/200\n",
            "8/8 [==============================] - 2s 264ms/step - loss: 3.4791e-05 - accuracy: 1.0000 - val_loss: 0.3889 - val_accuracy: 0.9684\n",
            "Epoch 152/200\n",
            "8/8 [==============================] - 2s 270ms/step - loss: 3.4214e-05 - accuracy: 1.0000 - val_loss: 0.3891 - val_accuracy: 0.9644\n",
            "Epoch 153/200\n",
            "8/8 [==============================] - 2s 264ms/step - loss: 3.2609e-05 - accuracy: 1.0000 - val_loss: 0.3902 - val_accuracy: 0.9644\n",
            "Epoch 154/200\n",
            "8/8 [==============================] - 2s 262ms/step - loss: 3.2331e-05 - accuracy: 1.0000 - val_loss: 0.3907 - val_accuracy: 0.9644\n",
            "Epoch 155/200\n",
            "8/8 [==============================] - 2s 262ms/step - loss: 3.1520e-05 - accuracy: 1.0000 - val_loss: 0.3911 - val_accuracy: 0.9644\n",
            "Epoch 156/200\n",
            "8/8 [==============================] - 2s 281ms/step - loss: 3.1449e-05 - accuracy: 1.0000 - val_loss: 0.3918 - val_accuracy: 0.9644\n",
            "Epoch 157/200\n",
            "8/8 [==============================] - 2s 262ms/step - loss: 3.0244e-05 - accuracy: 1.0000 - val_loss: 0.3929 - val_accuracy: 0.9644\n",
            "Epoch 158/200\n",
            "8/8 [==============================] - 2s 267ms/step - loss: 2.9840e-05 - accuracy: 1.0000 - val_loss: 0.3929 - val_accuracy: 0.9644\n",
            "Epoch 159/200\n",
            "8/8 [==============================] - 2s 267ms/step - loss: 2.9972e-05 - accuracy: 1.0000 - val_loss: 0.3946 - val_accuracy: 0.9644\n",
            "Epoch 160/200\n",
            "8/8 [==============================] - 2s 280ms/step - loss: 2.9049e-05 - accuracy: 1.0000 - val_loss: 0.3951 - val_accuracy: 0.9644\n",
            "Epoch 161/200\n",
            "8/8 [==============================] - 2s 262ms/step - loss: 2.8911e-05 - accuracy: 1.0000 - val_loss: 0.3956 - val_accuracy: 0.9644\n",
            "Epoch 162/200\n",
            "8/8 [==============================] - 2s 278ms/step - loss: 2.7701e-05 - accuracy: 1.0000 - val_loss: 0.3968 - val_accuracy: 0.9644\n",
            "Epoch 163/200\n",
            "8/8 [==============================] - 2s 262ms/step - loss: 2.7496e-05 - accuracy: 1.0000 - val_loss: 0.3956 - val_accuracy: 0.9644\n",
            "Epoch 164/200\n",
            "8/8 [==============================] - 2s 266ms/step - loss: 2.7027e-05 - accuracy: 1.0000 - val_loss: 0.3964 - val_accuracy: 0.9644\n",
            "Epoch 165/200\n",
            "8/8 [==============================] - 2s 269ms/step - loss: 2.6604e-05 - accuracy: 1.0000 - val_loss: 0.3968 - val_accuracy: 0.9644\n",
            "Epoch 166/200\n",
            "8/8 [==============================] - 2s 262ms/step - loss: 2.6224e-05 - accuracy: 1.0000 - val_loss: 0.3981 - val_accuracy: 0.9644\n",
            "Epoch 167/200\n",
            "8/8 [==============================] - 2s 261ms/step - loss: 2.5596e-05 - accuracy: 1.0000 - val_loss: 0.3985 - val_accuracy: 0.9644\n",
            "Epoch 168/200\n",
            "8/8 [==============================] - 2s 262ms/step - loss: 2.5442e-05 - accuracy: 1.0000 - val_loss: 0.3982 - val_accuracy: 0.9644\n",
            "Epoch 169/200\n",
            "8/8 [==============================] - 2s 261ms/step - loss: 2.4687e-05 - accuracy: 1.0000 - val_loss: 0.3991 - val_accuracy: 0.9644\n",
            "Epoch 170/200\n",
            "8/8 [==============================] - 2s 262ms/step - loss: 2.4326e-05 - accuracy: 1.0000 - val_loss: 0.3995 - val_accuracy: 0.9644\n",
            "Epoch 171/200\n",
            "8/8 [==============================] - 2s 269ms/step - loss: 2.3838e-05 - accuracy: 1.0000 - val_loss: 0.4012 - val_accuracy: 0.9644\n",
            "Epoch 172/200\n",
            "8/8 [==============================] - 2s 264ms/step - loss: 2.3492e-05 - accuracy: 1.0000 - val_loss: 0.4008 - val_accuracy: 0.9644\n",
            "Epoch 173/200\n",
            "8/8 [==============================] - 2s 263ms/step - loss: 2.3267e-05 - accuracy: 1.0000 - val_loss: 0.4014 - val_accuracy: 0.9644\n",
            "Epoch 174/200\n",
            "8/8 [==============================] - 2s 263ms/step - loss: 2.2938e-05 - accuracy: 1.0000 - val_loss: 0.4015 - val_accuracy: 0.9644\n",
            "Epoch 175/200\n",
            "8/8 [==============================] - 2s 261ms/step - loss: 2.2573e-05 - accuracy: 1.0000 - val_loss: 0.4029 - val_accuracy: 0.9644\n",
            "Epoch 176/200\n",
            "8/8 [==============================] - 2s 261ms/step - loss: 2.2203e-05 - accuracy: 1.0000 - val_loss: 0.4030 - val_accuracy: 0.9644\n",
            "Epoch 177/200\n",
            "8/8 [==============================] - 2s 281ms/step - loss: 2.1754e-05 - accuracy: 1.0000 - val_loss: 0.4030 - val_accuracy: 0.9644\n",
            "Epoch 178/200\n",
            "8/8 [==============================] - 2s 284ms/step - loss: 2.1620e-05 - accuracy: 1.0000 - val_loss: 0.4040 - val_accuracy: 0.9644\n",
            "Epoch 179/200\n",
            "8/8 [==============================] - 2s 262ms/step - loss: 2.1506e-05 - accuracy: 1.0000 - val_loss: 0.4035 - val_accuracy: 0.9644\n",
            "Epoch 180/200\n",
            "8/8 [==============================] - 2s 262ms/step - loss: 2.0776e-05 - accuracy: 1.0000 - val_loss: 0.4052 - val_accuracy: 0.9644\n",
            "Epoch 181/200\n",
            "8/8 [==============================] - 2s 261ms/step - loss: 2.0539e-05 - accuracy: 1.0000 - val_loss: 0.4053 - val_accuracy: 0.9644\n",
            "Epoch 182/200\n",
            "8/8 [==============================] - 2s 262ms/step - loss: 2.0301e-05 - accuracy: 1.0000 - val_loss: 0.4058 - val_accuracy: 0.9644\n",
            "Epoch 183/200\n",
            "8/8 [==============================] - 2s 284ms/step - loss: 1.9690e-05 - accuracy: 1.0000 - val_loss: 0.4061 - val_accuracy: 0.9644\n",
            "Epoch 184/200\n",
            "8/8 [==============================] - 2s 285ms/step - loss: 1.9697e-05 - accuracy: 1.0000 - val_loss: 0.4070 - val_accuracy: 0.9644\n",
            "Epoch 185/200\n",
            "8/8 [==============================] - 2s 263ms/step - loss: 1.9079e-05 - accuracy: 1.0000 - val_loss: 0.4074 - val_accuracy: 0.9644\n",
            "Epoch 186/200\n",
            "8/8 [==============================] - 2s 264ms/step - loss: 1.9363e-05 - accuracy: 1.0000 - val_loss: 0.4086 - val_accuracy: 0.9644\n",
            "Epoch 187/200\n",
            "8/8 [==============================] - 2s 260ms/step - loss: 1.8522e-05 - accuracy: 1.0000 - val_loss: 0.4088 - val_accuracy: 0.9644\n",
            "Epoch 188/200\n",
            "8/8 [==============================] - 2s 262ms/step - loss: 1.9006e-05 - accuracy: 1.0000 - val_loss: 0.4090 - val_accuracy: 0.9644\n",
            "Epoch 189/200\n",
            "8/8 [==============================] - 2s 282ms/step - loss: 1.7976e-05 - accuracy: 1.0000 - val_loss: 0.4092 - val_accuracy: 0.9644\n",
            "Epoch 190/200\n",
            "8/8 [==============================] - 2s 266ms/step - loss: 1.7906e-05 - accuracy: 1.0000 - val_loss: 0.4094 - val_accuracy: 0.9644\n",
            "Epoch 191/200\n",
            "8/8 [==============================] - 2s 265ms/step - loss: 1.7770e-05 - accuracy: 1.0000 - val_loss: 0.4100 - val_accuracy: 0.9644\n",
            "Epoch 192/200\n",
            "8/8 [==============================] - 2s 262ms/step - loss: 1.7244e-05 - accuracy: 1.0000 - val_loss: 0.4097 - val_accuracy: 0.9644\n",
            "Epoch 193/200\n",
            "8/8 [==============================] - 2s 262ms/step - loss: 1.7124e-05 - accuracy: 1.0000 - val_loss: 0.4108 - val_accuracy: 0.9644\n",
            "Epoch 194/200\n",
            "8/8 [==============================] - 2s 262ms/step - loss: 1.7657e-05 - accuracy: 1.0000 - val_loss: 0.4118 - val_accuracy: 0.9644\n",
            "Epoch 195/200\n",
            "8/8 [==============================] - 2s 263ms/step - loss: 1.6749e-05 - accuracy: 1.0000 - val_loss: 0.4121 - val_accuracy: 0.9644\n",
            "Epoch 196/200\n",
            "8/8 [==============================] - 2s 286ms/step - loss: 1.6476e-05 - accuracy: 1.0000 - val_loss: 0.4127 - val_accuracy: 0.9644\n",
            "Epoch 197/200\n",
            "8/8 [==============================] - 2s 266ms/step - loss: 1.6353e-05 - accuracy: 1.0000 - val_loss: 0.4138 - val_accuracy: 0.9644\n",
            "Epoch 198/200\n",
            "8/8 [==============================] - 2s 263ms/step - loss: 1.6052e-05 - accuracy: 1.0000 - val_loss: 0.4142 - val_accuracy: 0.9644\n",
            "Epoch 199/200\n",
            "8/8 [==============================] - 2s 262ms/step - loss: 1.5668e-05 - accuracy: 1.0000 - val_loss: 0.4134 - val_accuracy: 0.9644\n",
            "Epoch 200/200\n",
            "8/8 [==============================] - 2s 263ms/step - loss: 1.5407e-05 - accuracy: 1.0000 - val_loss: 0.4141 - val_accuracy: 0.9644\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcb998cf0a0>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "LeNet_model.fit(train_data2, train_label, batch_size=128, epochs=200, validation_split=0.2, shuffle=True, callbacks=[LeNet_checkpoint_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HuA5-g31atjb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a04caff-22ff-42b4-ebcd-5bfa9da521ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "317/317 - 1s - 846ms/epoch - 3ms/step\n",
            "Confusion matrix, without normalization\n",
            "[[75  0  2  1]\n",
            " [ 1 80  0  0]\n",
            " [ 0  0 68  0]\n",
            " [ 2  0  1 87]]\n",
            "Per class:  [0.96153846 0.98765432 1.         0.96666667]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "predictions_2 = LeNet_model.predict(\n",
        "      x=test_data\n",
        "    , batch_size=1\n",
        "    , verbose=2\n",
        ")\n",
        "\n",
        "# Rounding predictions values to map into confusion matrix\n",
        "rounded_predictions_2 = np.argmax(predictions_2, axis=-1)\n",
        "\n",
        "cm_plot_labels_2 = ['A', 'B', 'C', 'D']\n",
        "cm2 = confusion_matrix(y_true=test_label, y_pred=rounded_predictions_2)\n",
        "accuracy_2 = accuracy_score(test_label, rounded_predictions_2) * 100\n",
        "plot_confusion_matrix(cm=cm2, classes=cm_plot_labels_2, title=f'Confusion Matrix: LeNet. Accuracy {accuracy_2:.02f}%')\n",
        "print(\"Per class: \", cm2.diagonal()/cm2.sum(axis=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PZ1RiP9SBfR"
      },
      "source": [
        "# KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KeQTpvYMSWOw"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "from sklearn import neighbors, datasets\n",
        "from sklearn.model_selection import train_test_split # for splitting data\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxp77w_YSFP0"
      },
      "outputs": [],
      "source": [
        "def myweight(distances):\n",
        "  sigma2 = .4 # we can change this number\n",
        "  return np.exp(-distances**2/sigma2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H7ScZmN6SGOK"
      },
      "outputs": [],
      "source": [
        "#Tham so thu 3 co the la myweigt hoac distance\n",
        "model = neighbors.KNeighborsClassifier(n_neighbors = 7, p = 2, weights = myweight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoFuyINeSLMq",
        "outputId": "31682938-0fc1-467a-9be7-0b6ee8d5332f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of 7NN: 92.50 %\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model.fit(train_data, train_label)\n",
        "y_pred = model.predict(test_data)\n",
        "print(\"Accuracy of 7NN: %.2f %%\" %(100*accuracy_score(test_label, y_pred)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyX8EmlnXe3Z"
      },
      "source": [
        "# Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqkiQwHHXhQM"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8aXKtGeXiCH",
        "outputId": "ba9ba611-aa89-403c-c3ec-8e686eb5f521"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "58.4375\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "model = GaussianNB()\n",
        "model.partial_fit(train_data, train_label,np.unique(train_label))\n",
        "y_pred2 = model.predict(test_data)\n",
        "print(accuracy_score(test_label, y_pred2)*100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1q714H_L7Mpe"
      },
      "source": [
        "# Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qRTvkBB7QUV",
        "outputId": "96a4b0a3-8696-4a0f-818b-4072ac60045a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "79.0625\n"
          ]
        }
      ],
      "source": [
        "from sklearn import tree\n",
        "\n",
        "clf_tree = tree.DecisionTreeClassifier()\n",
        "clf_tree = clf_tree.fit(train_data, train_label)\n",
        "l = clf_tree.predict(test_data)\n",
        "print(accuracy_score(test_label, l)*100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IObbdBtCYCOM"
      },
      "source": [
        "# RANDOM FOREST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkvh6VA3YFCr",
        "outputId": "0a49ceef-4077-4af5-fe4f-48a2f531d15c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.621875\n",
            "1.0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model3 = RandomForestClassifier()\n",
        "model3.fit(train_data, train_label)\n",
        "print(model3.score(test_data, test_label))\n",
        "print(model3.score(train_data, train_label))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edkXQn9q2jio"
      },
      "source": [
        "# SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zw1wfHTk2l-e",
        "outputId": "0785acd4-2607-43af-8077-7cb68e0156f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "92.1875\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.svm import SVC\n",
        "clf = OneVsRestClassifier(SVC()).fit(train_data, train_label)\n",
        "y_pred2 = clf.predict(test_data)\n",
        "print(accuracy_score(test_label, y_pred2)*100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLen7_j3E3LW"
      },
      "outputs": [],
      "source": [
        "K-Means"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "YeXyo1mCn8Ar",
        "v2FpH2dqoKrz",
        "UYluQlZPaOEQ"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}